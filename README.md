# PublicDatasets
Research Project Repo on How Datasets are Cited @ PURRlab, [ITU Copenhagen](http://en.itu.dk/)

## At a glance
Machine learning challenges hosted on platforms such as Kaggle, grand-challenge.org, or CodaLab have attracted a lot of attention, both from academia and industry researchers. Challenge designs vary widely, including what type of data is available, how the algorithms are evaluated, and the rewards for the winners. In medical imaging, there is some evidence that challenges might be creating a shift in attention to different diseases, for example, there is a disproportionate increase in papers on lung cancer after the 2016 Kaggle challenge on the subject.

However, it is actually non-trivial to observe the impact these datasets have on research and technology. There are no well-defined conventions for citing most public datasets, which often come from outside of academic journals. The overall goal of this project is to understand how we can relate research to datasets they either use or are inspired by.

## Log

WIP

### The Story so Far:
My initial approach has been to work backwards: To first collect literature and _then to scan_ for mentions of corresponding datasets. This is solely motivated by the fact that there are a lot more tools to query literature.

The first dataset of interest comes from the [Kaggle Data Science Bowl '17](https://www.kaggle.com/c/data-science-bowl-2017). This was a lung-cancer tissue detection challenge with annotated data provided by The [National Lung Screening Trial](https://www.cancer.gov/types/lung/research/nlst), [Copenhagen University Hospital](https://universitetshospitalet.ku.dk/english/about/) and others. Arguably, the challenge and corresponding dataset inspired a new interest in lung cancer research; see [(Varoquaux & Cheplygina, 2022)](https://arxiv.org/pdf/2103.10292.pdf).