{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3ff45d6-f5c4-44fb-aef7-a9edc0596a90",
   "metadata": {},
   "source": [
    "# PublicDatasets (Analyser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4b8014-f228-46f3-a745-bfb4e63cbc60",
   "metadata": {},
   "source": [
    "## 1. Re-reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "17433dfb-a29b-4374-9112-0ad4afa2224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_separator = '___'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba056aa2-a5a2-4c12-923c-814b78cfa6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a553a422-2566-4a43-824b-6baaff9027d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_paper_table = pd.read_csv('data/ResearchPapers.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bd1b100a-f80d-4f13-ac61-88717d87a31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Venue</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHIL 2021</td>\n",
       "      <td>Practical Challenges in Differentially-Private...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHIL 2021</td>\n",
       "      <td>Disability prediction in multiple sclerosis us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHIL 2021</td>\n",
       "      <td>Data Augmentation for Electrocardiograms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHIL 2021</td>\n",
       "      <td>MedMCQA: A Large-scale Multi-Subject Multi-Cho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CHIL 2021</td>\n",
       "      <td>Improving the Fairness of Chest X-ray Classifiers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Venue                                              Title\n",
       "1  CHIL 2021  Practical Challenges in Differentially-Private...\n",
       "2  CHIL 2021  Disability prediction in multiple sclerosis us...\n",
       "3  CHIL 2021           Data Augmentation for Electrocardiograms\n",
       "4  CHIL 2021  MedMCQA: A Large-scale Multi-Subject Multi-Cho...\n",
       "5  CHIL 2021  Improving the Fairness of Chest X-ray Classifiers"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_paper_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d352189-d02b-4723-b92a-e14809c0863b",
   "metadata": {},
   "source": [
    "### 1.a get file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e7384f08-4eb9-4fac-97d1-83323d9f309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_filename(v,t,path='data/texts/'):\n",
    "    return path+v+special_separator+t+'.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3a0986de-9dc4-4b68-9f93-183afa7591d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for index, row in research_paper_table.iterrows():\n",
    "    texts.append(get_text_filename(row[\"Venue\"],row[\"Title\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1826af-7e31-4cce-8ea9-870b240621d7",
   "metadata": {},
   "source": [
    "## 2. Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d1ccae-ba20-4fa1-b3dc-c63b61345f12",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1 Explicit Mentions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c03b046d-8b2e-4309-9151-cb70347e2b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions = [\n",
    "    #'kaggle',\n",
    "    'competition',\n",
    "    #'grand',\n",
    "    'challenge',\n",
    "    'dataset',\n",
    "    'data set',\n",
    "    # 'datasets',\n",
    "    # 'data sets',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e88341a-1df1-446d-8972-68ddc540c40e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2 Related Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "82c8d246-8920-4d8a-8820-51d34e0c626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\n",
    "    # \"lung cancer\",\n",
    "    # \"nodule\",\n",
    "    # \"competition\",\n",
    "    # \"kaggle dataset\",\n",
    "    \"kaggle\",\n",
    "    # \"deep learning\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec4a0c0-67fe-4a63-907b-6589dd2fc228",
   "metadata": {},
   "source": [
    "## 3. Relation Queriers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc6afde-cc15-470e-a6b5-aa69358c095c",
   "metadata": {},
   "source": [
    "### 3.1 First Occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78541906-e640-4d1e-b4e4-2506a3d69f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_occurence_context(contents, low_name, preview_offset = 100):\n",
    "    idx=contents.find(low_name)\n",
    "    idx_end = idx + len(low_name)\n",
    "    L = len(contents)\n",
    "    start_edge = max(0,idx-preview_offset)\n",
    "    end_edge = min(L-1,idx+preview_offset)\n",
    "    print(\"\\33[32mFound\", name, \"in\", text_file,\":\\33[0m\",'\\n',\n",
    "          contents[start_edge:idx]+'\\033[5m\\u001b[31m'+contents[idx:idx_end]+'\\33[0m'+contents[idx_end:end_edge]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4348c61-612d-4a0a-bbc8-52501f1013c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFound competition in data/texts/CHIL 2021___Practical Challenges in Differentially-Private Federated Survival Analysis of Medical Data.txt :\u001b[0m \n",
      " hadiji, marc m¨uller, youngjun joo,\n",
      "jiyeon lee, inchon hwang, and kyung-joong kim.\n",
      "game data mining \u001b[5m\u001b[31mcompetition\u001b[0m on churn prediction\n",
      "and survival analysis using commercial game log data.\n",
      "ieee transacti\n",
      "\u001b[32mFound competition in data/texts/CHIL 2021___MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering.txt :\u001b[0m \n",
      " e answer’s explanation. (✓ : the correct answer)\n",
      "\n",
      "et al., 2020) and the organization of workshops &\n",
      "\u001b[5m\u001b[31mcompetition\u001b[0ms such as the question answering in the\n",
      "medical domain & bioasq challenge (abacha et al.,\n",
      "\u001b[32mFound competition in data/texts/CHIL 2021___ADCB: An Alzheimer’s disease simulator for benchmarking observational estimators of causal effects.txt :\u001b[0m \n",
      "  automated versus do-it-yourself\n",
      "methods for causal inference: lessons learned from\n",
      "a data analysis \u001b[5m\u001b[31mcompetition\u001b[0m. statistical science, 34\n",
      "(1):43–68, 2019.\n",
      "\n",
      "martin r farlow, michael l miller, and vojisl\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Conference on Health, Inference, and Learning (CHIL) 2022.txt :\u001b[0m \n",
      " lated areas. the goal of the con-\n",
      "ference is to foster excellent research that addresses\n",
      "the unique \u001b[5m\u001b[31mchallenge\u001b[0ms and opportunities that arise at\n",
      "the intersection of machine learning and health.\n",
      "\n",
      "2. conf\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Practical Challenges in Differentially-Private Federated Survival Analysis of Medical Data.txt :\u001b[0m \n",
      " ng research 174:411–425, 2022\n",
      "\n",
      "conference on health, inference, and learning (chil) 2022\n",
      "\n",
      "practical \u001b[5m\u001b[31mchallenge\u001b[0ms in differentially-private federated survival analysis\n",
      "of medical data\n",
      "\n",
      "shadi rahimian\n",
      "cis\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering.txt :\u001b[0m \n",
      " anization of workshops &\n",
      "competitions such as the question answering in the\n",
      "medical domain & bioasq \u001b[5m\u001b[31mchallenge\u001b[0m (abacha et al.,\n",
      "2019; nentidis et al., 2020)\n",
      "\n",
      "however, despite these successful efforts, a\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Improving the Fairness of Chest X-ray Classifiers.txt :\u001b[0m \n",
      " ayena, alessandro blasimme, and i glenn co-\n",
      "hen. machine learning in medicine: addressing eth-\n",
      "ical \u001b[5m\u001b[31mchallenge\u001b[0ms. plos medicine, 15(11):e1002689,\n",
      "2018.\n",
      "\n",
      "sahil verma and julia rubin. fairness definitions\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Context-Sensitive Spelling Correction of Clinical Text via Conditional Independence.txt :\u001b[0m \n",
      " agnosis codes given the\n",
      "clinical note).\n",
      "\n",
      "such spelling correction in a clinical context has\n",
      "several \u001b[5m\u001b[31mchallenge\u001b[0ms. first, the candidate generation\n",
      "step, a critical component of most spelling correc-\n",
      "tion\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___How to validate Machine Learning Models Prior to Deployment: Silent trial protocol for evaluation of real-time models at ICU.txt :\u001b[0m \n",
      " oration pathway (blackwell et al.,\n",
      "2020; erez et al., 2021; rusin et al., 2016) poses a\n",
      "significant \u001b[5m\u001b[31mchallenge\u001b[0m in the evaluation of risk mod-\n",
      "\n",
      "els. during the retrospective validation phase of the\n",
      "mode\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Uncertainty-Aware Text-to-Program for Question Answering on Structured Electronic Health Records.txt :\u001b[0m \n",
      " s\n",
      "works proposed reinforcement learning (rl) based\n",
      "approaches.\n",
      "\n",
      "rl-based approaches, however,\n",
      "\n",
      "face \u001b[5m\u001b[31mchallenge\u001b[0ms\n",
      "caused by the large search space and sparse rewards.\n",
      "in particular, these challenges are \n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___ADCB: An Alzheimer’s disease simulator for benchmarking observational estimators of causal effects.txt :\u001b[0m \n",
      " ager\n",
      "and athey, 2018) for overviews. to assess the quali-\n",
      "ties of each estimator, various benchmark \u001b[5m\u001b[31mchallenge\u001b[0ms\n",
      "have been developed (dorie et al., 2019). see sec-\n",
      "tion 6 for a more in-depth survey.\n",
      "\n",
      "fu\n"
     ]
    }
   ],
   "source": [
    "mention_matches = {name:[] for name in mentions}\n",
    "\n",
    "limit = 10\n",
    "for name in mentions:\n",
    "    i=0\n",
    "    for text_file in texts:\n",
    "        if i>limit: break\n",
    "        with open(text_file, 'r') as f:\n",
    "            contents = f.read()\n",
    "            #Only check for 1-for-1 correspondence\n",
    "            #AND DON'T FORGET TO LOWER CASE WHEN COMPARING!\n",
    "            contents = contents.lower()\n",
    "            low_name=name.lower()\n",
    "            if contents.find(low_name) != -1:\n",
    "                mention_matches[name].append(1)\n",
    "                get_first_occurence_context(contents, low_name)\n",
    "            else:\n",
    "                mention_matches[name].append(0)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96962576-45d8-434b-94aa-f0e583726445",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_matches = {keyword:[] for keyword in keywords}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edc8cc2d-bfc8-4edd-bc24-fed3563102f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIPPING\n",
    "# for keyword in keywords:\n",
    "#     for text_file in texts:\n",
    "#         with open(text_file, 'r') as f:\n",
    "#             contents = f.read()\n",
    "#             #Only check for 1-for-1 correspondence\n",
    "#             #AND DON'T FORGET TO LOWER CASE WHEN COMPARING!\n",
    "#             contents = contents.lower()\n",
    "#             low_key=keyword.lower()\n",
    "#             if contents.find(low_key) != -1:\n",
    "#                 keyword_matches[keyword].append(1)\n",
    "#                 idx=contents.find(low_key)\n",
    "#                 print(\"Found\", keyword, \"in\", text_file,\":\",contents[idx-preview_offset:idx+preview_offset])\n",
    "#             else:\n",
    "#                 keyword_matches[keyword].append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf70179-e276-4aab-9507-b7b46ffe826d",
   "metadata": {},
   "source": [
    "### 3.2 First Occurence in Bibliography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bba220c-ae3f-424f-a482-807d9b9d2cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_occurence_context_after(contents, low_name, after='', preview_offset = 100):\n",
    "    idx0=contents.rfind(after)\n",
    "    idx=contents.find(low_name,idx0)\n",
    "    idx_end = idx + len(low_name)\n",
    "    L = len(contents)\n",
    "    start_edge = max(0,idx-preview_offset)\n",
    "    end_edge = min(L-1,idx+preview_offset)\n",
    "    print(\"\\33[32mFound\", name, \"in\", text_file,\":\\33[0m\",'\\n',\n",
    "          contents[start_edge:idx]+'\\033[5m\\u001b[31m'+contents[idx:idx_end]+'\\33[0m'+contents[idx_end:end_edge]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2397011b-6a3d-4654-a981-5d2d2ea5461a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFound competition in data/texts/CHIL 2021___Practical Challenges in Differentially-Private Federated Survival Analysis of Medical Data.txt :\u001b[0m \n",
      " hadiji, marc m¨uller, youngjun joo,\n",
      "jiyeon lee, inchon hwang, and kyung-joong kim.\n",
      "game data mining \u001b[5m\u001b[31mcompetition\u001b[0m on churn prediction\n",
      "and survival analysis using commercial game log data.\n",
      "ieee transacti\n",
      "\u001b[32mFound competition in data/texts/CHIL 2021___ADCB: An Alzheimer’s disease simulator for benchmarking observational estimators of causal effects.txt :\u001b[0m \n",
      "  automated versus do-it-yourself\n",
      "methods for causal inference: lessons learned from\n",
      "a data analysis \u001b[5m\u001b[31mcompetition\u001b[0m. statistical science, 34\n",
      "(1):43–68, 2019.\n",
      "\n",
      "martin r farlow, michael l miller, and vojisl\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Practical Challenges in Differentially-Private Federated Survival Analysis of Medical Data.txt :\u001b[0m \n",
      " proceedings of machine learning research 174:411–425, 2022\n",
      "\n",
      "conference on health, inference, and learning (chil) 2022\n",
      "\n",
      "practical challenges in differentially-private federated survival analysis\n",
      "of medical data\n",
      "\n",
      "shadi rahimian\n",
      "cispa helmholtz center for information security, germany\n",
      "\n",
      "raouf kerkouche\n",
      "cispa helmholtz center for information security, germany\n",
      "\n",
      "ina kurth\n",
      "dkfz german cancer research center, germany\n",
      "\n",
      "mario fritz\n",
      "cispa helmholtz center for information security, germany\n",
      "\n",
      "shadi.rahimian@cispa.saarland\n",
      "\n",
      "raouf.kerkouche@cispa.de\n",
      "\n",
      "ina.kurth@dkfz-heidelberg.de\n",
      "\n",
      "fritz@cispa.de\n",
      "\n",
      "abstract\n",
      "\n",
      "survival analysis or time-to-event analysis aims\n",
      "to model and predict the time it takes for an\n",
      "event of interest to happen in a population or\n",
      "an individual. in the medical context this event\n",
      "might be the time of dying, metastasis, recur-\n",
      "rence of cancer, etc. recently, the use of neural\n",
      "networks that are specifically designed for sur-\n",
      "vival analysis has become more popular and an\n",
      "attractive alternative to more traditional meth-\n",
      "ods.\n",
      "in this paper, we take advantage of the\n",
      "inherent properties of neural networks to feder-\n",
      "ate the process of training of these models. this\n",
      "is crucial in the medical domain since data is\n",
      "scarce and collaboration of multiple health cen-\n",
      "ters is essential to make a conclusive decision\n",
      "about the properties of a treatment or a dis-\n",
      "ease. to ensure the privacy of the datasets, it\n",
      "is common to utilize differential privacy on top\n",
      "of federated learning. differential privacy acts\n",
      "by introducing random noise to different stages\n",
      "of training, thus making it harder for an adver-\n",
      "sary to extract details about the data. however,\n",
      "in the realistic setting of small medical datasets\n",
      "and only a few data centers, this noise makes it\n",
      "harder for the models to converge. to address\n",
      "this problem, we propose dpfed-post which\n",
      "adds a post-processing stage to the private fed-\n",
      "erated learning scheme. this extra step helps\n",
      "to regulate the magnitude of the noisy average\n",
      "parameter update and easier convergence of the\n",
      "model. for our experiments, we choose 3 real-\n",
      "world datasets in the realistic setting when each\n",
      "health center has only a few hundred records,\n",
      "and we show that dpfed-post successfully in-\n",
      "creases the performance of the models by an\n",
      "\n",
      "average of up to 17% compared to the standard\n",
      "differentially private federated learning scheme.\n",
      "\n",
      "data and code availability the pre-processed data\n",
      "for our experiments can be obtained through the py-\n",
      "cox package 1. we also submit our code as supple-\n",
      "mental material alongside this paper.\n",
      "\n",
      "1. introduction\n",
      "\n",
      "survival analysis or event history analysis is an old\n",
      "branch of statistics dating back to the 17th cen-\n",
      "tury (camilleri, 2019). the goal of survival analy-\n",
      "sis is to predict the time an event of interest occurs.\n",
      "this event can be the time of death of a patient(e.g.\n",
      "goldhirsch et al., 1989; brenner, 2002), the time of\n",
      "default for a bank customer(e.g. baesens et al., 2005;\n",
      "dirick et al., 2017; stepanova and thomas, 2002;\n",
      "laitinen, 2005), time of unsubscribing from an on-\n",
      "line service(e.g. mishachandar and kumar, 2018; lu,\n",
      "2002; lee et al., 2019), time until a mechanical system\n",
      "fails(e.g. hanson, 2004; styc and lagacherie, 2016)\n",
      "and so on. the assumption is that for each popula-\n",
      "tion, there is a mapping from the observed features of\n",
      "the individuals and their time of event. survival anal-\n",
      "ysis tools are used to learn this mapping from past\n",
      "data that have experienced the event and generalize\n",
      "to the whole population.\n",
      "\n",
      "as for any predictive model, it is important to have\n",
      "enough data points to achieve generalization. this is\n",
      "especially of great significance in the case of medical\n",
      "data with many outliers and complicated patterns.\n",
      "however, data is sparse and usually the centers that\n",
      "\n",
      "1. https://github.com/havakv/pycox\n",
      "\n",
      "© 2022 s. rahimian, r. kerkouche, i. kurth & m. fritz.\n",
      "\n",
      "\f",
      "collect these data (e.g. hospitals or banks) are re-\n",
      "luctant or not allowed to share their data with each\n",
      "other due to privacy and security reasons.\n",
      "\n",
      "this calls for federated learning in the case of sur-\n",
      "vival analysis. federated learning mcmahan et al.\n",
      "(2017) grants the data owners the possibility of keep-\n",
      "ing their data locally, but participate in training of a\n",
      "global model, jointly, with other data owners. this\n",
      "is achievable by choosing a trusted central server and\n",
      "a machine learning model that is trained locally by\n",
      "each participant. the role of the central server is to\n",
      "iteratively collect these trained models, update the\n",
      "global model based on the updated local models and\n",
      "share the updated global model with participants.\n",
      "despite the obvious benefits of learning survival mod-\n",
      "els in a federated setting, there has been no study on\n",
      "the practical effects of federation on survival analysis\n",
      "tools.\n",
      "\n",
      "although federated learning provides a scheme in\n",
      "which no direct sharing of data is required, there is\n",
      "still the risk of information leakage through parame-\n",
      "ters/output of the model. it has been shown that an\n",
      "adversary can carry out successful reconstruction at-\n",
      "tacks (zhu et al., 2019; geiping et al., 2020), member-\n",
      "ship inference attacks (nasr et al., 2019; melis et al.,\n",
      "2019) and feature leakage attacks (melis et al., 2019).\n",
      "one solution for protecting the privacy of these\n",
      "models and their training data is to utilize differen-\n",
      "tial privacy (dp) (dwork and roth, 2014). dp of-\n",
      "fers privacy through a noise addition mechanism and\n",
      "is based on rigorous theoretical guarantees against\n",
      "data information leakage.\n",
      "in federated learning,\n",
      "dp can be directly applied on the clients side such\n",
      "that any record in any dataset of any client is pro-\n",
      "tected (record-level dp e.g.\n",
      "in truex et al., 2020;\n",
      "kerkouche et al., 2021c) or it can be applied on the\n",
      "updates that are shared by each client with the cen-\n",
      "tral server such that the client’s dataset as a whole is\n",
      "protected. (client-level dp e.g. in geyer et al., 2017).\n",
      "the latter is preferable as it provides tighter privacy\n",
      "gurantees.\n",
      "\n",
      "in this paper, we focus on real-world challenges of\n",
      "dp federated learning of survival models for medi-\n",
      "cal data, where data and also the number of clients\n",
      "that participate in the federated learning is limited.\n",
      "here, the noise of client-level dp - which scales pro-\n",
      "portional to the client sampling probability - is so\n",
      "large that it prevents the model from converging. to\n",
      "tackle this problem, we take advantage of the post-\n",
      "processing property of differential privacy and make\n",
      "an additional step of clipping the noisy average up-\n",
      "\n",
      "date of clients by a reasonable value. this method\n",
      "can be viewed as using a regularization for the learn-\n",
      "ing rate of the global model.\n",
      "our contributions are:\n",
      "\n",
      "• we evaluate the effect of federation of survival\n",
      "\n",
      "models on real-world datasets\n",
      "\n",
      "• we discuss what the challenges would be in fed-\n",
      "eration of these models for the realistic setting\n",
      "when a few clients each possessing only a few\n",
      "hundred data points wish to collaborate.\n",
      "\n",
      "• we successfully apply a post-processing step for\n",
      "client-level differentially-private federated learn-\n",
      "ing and observe that the performances of the\n",
      "model are consistently improved over different\n",
      "datasets and models when this trick is used.\n",
      "\n",
      "2. background\n",
      "\n",
      "in this section, we will give an overview of all the\n",
      "necessary concepts to understand our approach. we\n",
      "first describe survival analysis in a more formal way\n",
      "and introduce some traditional methods that are used\n",
      "for time-to-event prediction. we explain why in the\n",
      "medical setting it is important that multiple parties\n",
      "collaborate and share their data such that a richer,\n",
      "more generalizable model can be learned.\n",
      "\n",
      "we then introduce federated learning which is a\n",
      "well-motivated and popular solution to collaborative\n",
      "training of models. by using federated learning, dif-\n",
      "ferent parties each holding their own dataset can\n",
      "jointly train a unified model.\n",
      "\n",
      "naturally, collaborative training of a model\n",
      "\n",
      "is\n",
      "prone to privacy breaches.\n",
      "so at last we give a\n",
      "brief overview of differential privacy as a privacy-\n",
      "preserving method that can be deployed on top of\n",
      "federated learning.\n",
      "\n",
      "2.1. survival analysis\n",
      "\n",
      "survival analysis is the collection of the tools for\n",
      "analysing and predicting the time duration until a\n",
      "specific event happens. for example, in the case of\n",
      "clinical data, this event can be the time of death for\n",
      "the patients.\n",
      "the survival function s(t) and the cumulative inci-\n",
      "dence function (cif) f (t) can be defined as follows:\n",
      "\n",
      "s(t) = p(t > t) = 1 − f (t)\n",
      "\n",
      "(1)\n",
      "\n",
      "412\n",
      "\n",
      "\f",
      "where p(t > t) indicates the probability that the\n",
      "event of interest t happens after time t. so the sur-\n",
      "vival function is interpreted as the probability of the\n",
      "event happening after time t and the complementary\n",
      "cif is the probability of the event happening before\n",
      "or at time t. we can also define the hazard rate h(t):\n",
      "\n",
      "h(t) = lim\n",
      "∆t→0\n",
      "\n",
      "1\n",
      "∆t\n",
      "\n",
      "p(t ≤ t < t + ∆t|t ≥ t)\n",
      "\n",
      "(2)\n",
      "\n",
      "thus the survival function can be calculated from the\n",
      "hazard rate by:\n",
      "\n",
      "model, first the coefficients β are found by maximizing\n",
      "the partial log likelihood of the model:\n",
      "\n",
      "(cid:18)\n",
      "\n",
      "l = πi\n",
      "\n",
      "exp[g(xi)]\n",
      "\n",
      "(cid:19)ei\n",
      "\n",
      "p\n",
      "\n",
      "j∈ri\n",
      "\n",
      "exp[g(xj)]\n",
      "\n",
      "(6)\n",
      "\n",
      "where ri is the risk set of all individuals at risk at time\n",
      "ti.\n",
      "\n",
      "in the second step, the baseline hazard is estimated for\n",
      "\n",
      "the parameters found in the first step.\n",
      "\n",
      "the proportionality in the name of this model comes\n",
      "from the fact that for two data points xi and xj the haz-\n",
      "ard ratio remains constant over time:\n",
      "\n",
      "s(t) = exp[−\n",
      "\n",
      "z t\n",
      "\n",
      "0\n",
      "\n",
      "h(s)ds] = exp[−h(t)],\n",
      "\n",
      "(3)\n",
      "\n",
      "h(t|xi)\n",
      "h(t|xj)\n",
      "\n",
      "= h0(t)g(xi)\n",
      "h0(t)g(xj)\n",
      "\n",
      "= g(xi)\n",
      "g(xj)\n",
      "\n",
      "(7)\n",
      "\n",
      "where h(t) is called the cumulative hazard. we can\n",
      "observe that having one of these functions is adequate\n",
      "to calculate the others, but each offers a unique per-\n",
      "spective into the survival status of the data.\n",
      "\n",
      "for real-world data, the event we are interested in,\n",
      "e.g. death or recovery, may not be observed for all\n",
      "data points. this can happen when, for example, the\n",
      "patient does not participate in the follow-ups, or they\n",
      "die due to a cause unrelated to the original study, or\n",
      "simply when they have not yet experienced the event\n",
      "of interest at the last follow-up of the study. these\n",
      "data points are said to be right-censored. so the time\n",
      "of event is chosen as t = min{t ∗, c}, where t ∗ is\n",
      "the true time of event for the individual and c is the\n",
      "time of censoring. survival data usually comes in the\n",
      "form of:\n",
      "\n",
      "to summarize, the main goal of survival analysis is to\n",
      "model the relationship between the vector of features of\n",
      "the data points and the time that an event of interest\n",
      "happens. this model is fitted on a set of data points that\n",
      "we assume is representative of the statistical properties\n",
      "of a population. the more datapoints are used to fit the\n",
      "model, the more generalizable the model will be, as each\n",
      "datapoint adds more information about the properties of\n",
      "the population.\n",
      "\n",
      "unfortunately, the collection of data is expensive and\n",
      "time consuming for the health centers, and the number\n",
      "of patients they receive is also limited. this means that\n",
      "by using only the data of one health center, we would\n",
      "have a high bias and the fitted model would not be well-\n",
      "generalizable. as a solution for this problem, we look\n",
      "at the federated learning for survival models, in the next\n",
      "section. federated learning allows multiple data-holders\n",
      "to jointly learn a model over the union of their data.\n",
      "\n",
      "x = {xi, yi}n\n",
      "\n",
      "i=1 = {xi, ti, ei}n\n",
      "i=1\n",
      "\n",
      "(4)\n",
      "\n",
      "2.2. federated learning\n",
      "\n",
      "for n individuals. here, xi and yi are the vector of\n",
      "covariates or features and the label for data point i,\n",
      "respectively. the features vector can, for example,\n",
      "contain information about the age, gender, medical\n",
      "history, tumor size, etc. for medical data. yi can fur-\n",
      "ther be decomposed into the tuple of {ti, ei} where\n",
      "ti is the time of event for the event type ei for indi-\n",
      "vidual i. it is customary to set e = 0 for individuals\n",
      "that are right-censored.\n",
      "\n",
      "given this set x , one way to calculate the survival\n",
      "functions is by cox proportional hazards (cox, 1972)\n",
      "model:\n",
      "\n",
      "h(t|x) = h0(t)g(x)\n",
      "\n",
      "where\n",
      "\n",
      "g(x) = βt x\n",
      "\n",
      "(5)\n",
      "\n",
      "the main assumption of the cox proportional hazards\n",
      "model is that the features x are independent and a lin-\n",
      "ear combination of them and a non-parametric baseline\n",
      "hazard h0(t) are sufficient to model the data. to fit this\n",
      "\n",
      "one of the major issues for modeling survival data is the\n",
      "lack of enough training data. oftentimes many separate\n",
      "data owners have access to limited amounts of data and\n",
      "due to reasons, such as privacy and security, are unwill-\n",
      "ing to simply share their data with each other to learn a\n",
      "richer model. this is where federated learning mcmahan\n",
      "et al. (2017); shokri and shmatikov (2015) becomes im-\n",
      "portant. federated learning is the concept of distributing\n",
      "the learning process of machine learning models among\n",
      "several data owners, without the need to access their lo-\n",
      "cal data.\n",
      "\n",
      "in this paper we use deep neural networks designed for\n",
      "survival analysis as the model that we wish to federate.\n",
      "in general to train a deep neural network, an objective\n",
      "function is optimized over the parameters of the model,\n",
      "w, for a training dataset which contains n data points:\n",
      "\n",
      "min\n",
      "w\n",
      "\n",
      "f (w) where f (w) =\n",
      "\n",
      "1\n",
      "\n",
      "n\n",
      "\n",
      "n\n",
      "x\n",
      "\n",
      "i=1\n",
      "\n",
      "l(xi, yi; w)\n",
      "\n",
      "(8)\n",
      "\n",
      "413\n",
      "\n",
      "\f",
      "where l(xi, yi; w) is the loss function for i-th data point\n",
      "with label yi, and the training is done iteratively over the\n",
      "dataset. therefore by defining the appropriate loss func-\n",
      "tion for survival analysis tasks, we can train the network\n",
      "to capture the behavior of the stochastic processes from\n",
      "the training set.\n",
      "\n",
      "in federated learning a central server holds a global\n",
      "model which is also shared with all the clients. clients\n",
      "locally and only send their updated\n",
      "train this model\n",
      "model parameters to the central server. the server up-\n",
      "dates the parameters of the global model with a weighted\n",
      "average of the local parameters and re-shares the updated\n",
      "global model with the clients. to reduce the cost of com-\n",
      "munication and computation, usually at each round, only\n",
      "a fraction of clients, c = k/n , are chosen randomly to\n",
      "train their local model. here c is the sampling probabil-\n",
      "ity of clients, k is the number of clients chosen out of a\n",
      "total of n clients at each round:\n",
      "\n",
      "pk\n",
      "\n",
      "k=1\n",
      "\n",
      "(9)\n",
      "\n",
      "wr ← wr−1 +\n",
      "\n",
      "(wr\n",
      "k − wr−1)\n",
      "k\n",
      "is the model parameters for client k after the r-\n",
      "where wr\n",
      "k\n",
      "th round of communication with the central server. these\n",
      "steps are done for a total number of tcl communica-\n",
      "tion rounds. the local parameters wr\n",
      "are computed by\n",
      "k\n",
      "each client using the standard training algorithms, such\n",
      "as stochastic gradient decent (robbins and monro, 1951;\n",
      "kiefer and wolfowitz, 1952). here, it is assumed that\n",
      "each client possesses nk training data and total number\n",
      "of data points can be calculated as n = pk\n",
      "\n",
      "although federated learning improves privacy by de-\n",
      "sign, model parameters can leak information about the\n",
      "training data.\n",
      "indeed, zhu et al. (2019); zhao et al.\n",
      "(2020); geiping et al. (2020) presented some attacks that\n",
      "allow an adversary to reconstruct some training data sam-\n",
      "ples of some entities. nasr et al. (2019); melis et al. (2019)\n",
      "define a membership attack that allows to infer if a par-\n",
      "ticular record is included in the data of a specific entity.\n",
      "similarly, melis et al. (2019) define an attack which aims\n",
      "at inferring if a group of people with a specific property,\n",
      "like for example skin color or ethnicity, is included in the\n",
      "dataset of a particular participating entity. a solution\n",
      "to prevent these attacks and provide theoretical guaran-\n",
      "tees in to use a privacy model called differential privacy\n",
      "(dwork and roth, 2014).\n",
      "\n",
      "k=1 nk.\n",
      "\n",
      "2.3. differential privacy\n",
      "\n",
      "differential privacy (dp) allows an entity to privately re-\n",
      "lease information about a dataset: a function of a record\n",
      "dataset is perturbed, so that any information which can\n",
      "differentiate this record from the rest of the dataset is\n",
      "bounded dwork and roth (2014).\n",
      "\n",
      "privacy loss of a with datasets d and d′ at output\n",
      "o ∈ range(a) is a random variable p(a, d, d′, o) =\n",
      "log pr[a(d)=o]\n",
      "pr[a(d′)=o] where the probability is taken on the ran-\n",
      "domness of a.\n",
      "\n",
      "definition 2 ((ϵ, δ)-differential privacy) a privacy mech-\n",
      "anism a guarantees (ε, δ)-differential privacy if for any\n",
      "database d and d′, differing on at most one record,\n",
      "pro∼a(d)[p(a, d, d′, o) > ε] ≤ δ dwork and roth\n",
      "(2014).\n",
      "\n",
      "this guarantees that an adversary, who has access to\n",
      "the output of a, can draw almost the same conclusions\n",
      "up to ε (with probability larger than 1 − δ) about any\n",
      "record no matter if it is included in the input of a or not.\n",
      "differential privacy main-\n",
      "moments accountant.\n",
      "tains composition;\n",
      "the privacy guarantee of the k-\n",
      "fold adaptive composition of a1:k = a1, . . . , ak can\n",
      "be computed using the moments accountant method\n",
      "abadi et al. (2016).\n",
      "it follows from\n",
      "markov’s inequality that pr[p(a, d, d′, o) ≥ ε] ≤\n",
      "e[exp(λp(a, d, d′, o))]/exp(λε) for any output o ∈\n",
      "range(a) and λ > 0. a is (ε, δ)-dp with δ =\n",
      "minλ exp(αa(λ) − λε), where αa(λ) =\n",
      "maxd,d′ log eo∼a(d)[exp(λp(a, d, d′, o))] is the log of\n",
      "the moment generating function of the privacy loss. the\n",
      "privacy guarantee of the composite mechanism a1:k can\n",
      "be calculated using that αa1:k\n",
      "(λ) abadi\n",
      "et al. (2016).\n",
      "\n",
      "(λ) ≤ pk\n",
      "\n",
      "in particular,\n",
      "\n",
      "i=1 αai\n",
      "\n",
      "gaussian mechanism. a fundamental concept of all dp\n",
      "sanitization techniques is the global sensitivity of a func-\n",
      "tion (dwork and roth, 2014).\n",
      "\n",
      "definition 3 (global lp-sensitivity) for any function f :\n",
      "d → rn,\n",
      "is ∆pf =\n",
      "the lp-sensitivity of f\n",
      "maxd,d′ ||f (d) − f (d′)||p, for all d, d′ differing in at\n",
      "most one record, where ||·||p denotes the lp-norm.\n",
      "the gaussian mechanism (dwork and roth, 2014) con-\n",
      "sists of adding gaussian noise to the true output of a\n",
      "function.\n",
      "in particular, for any function f : d → rn,\n",
      "the gaussian mechanism is defined as adding i.i.d gaus-\n",
      "sian noise with variance (∆2f · σ)2 and zero mean to\n",
      "each coordinate value of f (d). recall that the pdf of\n",
      "the gaussian distribution with mean µ and variance ξ2 is\n",
      "− (x−µ)2\n",
      "pdf g(µ,ξ)\n",
      "2ξ2\n",
      "in fact, the gaussian mechanism draws vector val-\n",
      "ues from a multivariate spherical (or isotropic) gaus-\n",
      "sian distribution which is described by random variable\n",
      "g(f (d), ∆2f · σin), where n is omitted if its unambiguous\n",
      "in the given context.\n",
      "\n",
      "(x) = 1√\n",
      "\n",
      "exp\n",
      "\n",
      "2πξ\n",
      "\n",
      "(cid:16)\n",
      "\n",
      "(cid:17)\n",
      "\n",
      ".\n",
      "\n",
      "3. approach\n",
      "\n",
      "definition 1 (privacy loss) let a be a privacy mechanism\n",
      "which assigns a value range(a) to a dataset d. the\n",
      "\n",
      "the most successful research in privacy-preserving fed-\n",
      "ereted learning has been studied on huge datasets, con-\n",
      "\n",
      "414\n",
      "\n",
      "\f",
      "taining up to millions of data records and hundreds of\n",
      "clients (see e.g. kairouz et al., 2019; augenstein et al.,\n",
      "2019; mcmahan et al., 2017; truex et al., 2019). however,\n",
      "in the realistic setting of medical application, the data is\n",
      "very scarce and the number of clients that are willing to\n",
      "collaborate, i.e. health centers, is also limited. this poses\n",
      "problems such as instability of results as well as sensitivity\n",
      "of the model to the dp noise when a privacy-preserving\n",
      "solution is needed.\n",
      "\n",
      "in this section, we first define the privacy model and the\n",
      "layer we choose to add differential privacy to, then discuss\n",
      "the problems that this noise would cause in the case of\n",
      "small datasets. we propose our post-processing technique\n",
      "which does not change the dp guarantees, however, acts\n",
      "as a regularization on the learning rate thus stabilizing the\n",
      "convergence of the model during the federated training.\n",
      "\n",
      "finally, we present our experiments using 4 different\n",
      "survival deep neural networks and compare the results\n",
      "we obtain by federation, differentially private federation\n",
      "as well as applying the post-processing step.\n",
      "\n",
      "algorithm 1\n",
      "differentially private federated learning\n",
      "with post processing (dpfed-post).\n",
      "n total clients, local mini-batch size b, local epochs\n",
      "learning rate η,\n",
      "e, communication rounds tcl,\n",
      "sensitivity s and post-processing parameter p .\n",
      "initialize w0 and send the model to clients\n",
      "for r = 1, ...tcl\n",
      "\n",
      "wr\n",
      "∆wr\n",
      "∆ ˆwr\n",
      "\n",
      "select k clients randomly\n",
      "for each selected client k = 1, ..., k\n",
      "k ← clientupdate(k, wr−1)\n",
      "k − wr−1\n",
      "(cid:16)\n",
      "1, ||∆wr\n",
      "k/max\n",
      "∆ ˆwr\n",
      "k+g(0,sσi)\n",
      "∆wr ←\n",
      "k\n",
      "(cid:16)\n",
      "∆ ˆwr ← ∆wr/max\n",
      "wr ← wr−1 + ∆ ˆwr\n",
      "\n",
      "k ← wr\n",
      "k ← ∆wr\n",
      "pk\n",
      "\n",
      "1, ||∆wr ||2\n",
      "\n",
      "k||2\n",
      "\n",
      "k=1\n",
      "\n",
      "(cid:17)\n",
      "\n",
      "p\n",
      "\n",
      "s\n",
      "\n",
      "(cid:17)\n",
      "\n",
      "clientupdate(k, w)\n",
      "for client k\n",
      "for i = 1, ..., e\n",
      "\n",
      "for local batches b\n",
      "\n",
      "w ← w − η∇l(b; w)\n",
      "\n",
      "return w to server\n",
      "\n",
      "3.1. privacy model\n",
      "\n",
      "we consider an adversary, or a set of colluding adver-\n",
      "saries, who can access any update vector sent by the server\n",
      "at each round of the protocol. a plausible adversary is a\n",
      "participating entity, i.e. a malicious client, that wants to\n",
      "infer the training data used by other participants. we as-\n",
      "\n",
      "sume that the server is trusted. the adversary is passive\n",
      "(i.e., honest-but-curious), that is, it follows the learning\n",
      "protocol faithfully.\n",
      "\n",
      "different privacy requirements can be considered de-\n",
      "pending on what information the adversary aims to infer.\n",
      "in general, private information can be inferred about:\n",
      "\n",
      "• any record (user or patient) in any dataset of any\n",
      "\n",
      "client (record-level privacy),\n",
      "\n",
      "• any client/party (client-level privacy).\n",
      "to illustrate the above requirements, suppose that sev-\n",
      "eral hospitals build a common model to predict the risk\n",
      "of death for their patients. a hospital certainly does not\n",
      "want other hospitals to learn the status of any of their pa-\n",
      "tients (record privacy) and perhaps not even the average\n",
      "status of all their patients (client privacy).\n",
      "\n",
      "record-level privacy is a standard requirement used in\n",
      "the privacy literature, but it is weaker than client-level\n",
      "privacy. indeed, client-level privacy requires to hide any\n",
      "information which is unique to a client including perhaps\n",
      "all its training data.\n",
      "\n",
      "we aim at developing a solution that provides client-\n",
      "level privacy. for example, in the scenario of collabo-\n",
      "rating hospitals, we aim at protecting any information\n",
      "that is unique to each single hospital’s training data. the\n",
      "adversary should not be able to infer from the received\n",
      "model or its updates whether any client’s data is involved\n",
      "in the federated run (up to ε and δ). we believe that this\n",
      "adversarial model is reasonable in many practical appli-\n",
      "cations when the confidential information spans over mul-\n",
      "tiple samples in the training data of a single client (e.g.,\n",
      "the presence of a group a samples, such as people from\n",
      "a certain race). differential privacy guarantees plausible\n",
      "deniability not only to any groups of samples of a client\n",
      "but also to any client in the federated run. therefore,\n",
      "any negative privacy impact on a party (or its training\n",
      "samples) cannot be attributed to their involvement in the\n",
      "protocol run.\n",
      "\n",
      "3.2. dpfed-post: differentially private federated\n",
      "\n",
      "learning with post-processing\n",
      "\n",
      "3.2.1. challenge\n",
      "\n",
      "although standard differentially-private federated learn-\n",
      "ing (dpfed) generates a model which protects the dataset\n",
      "of each participant with a theoretical privacy guarantee\n",
      "(bounded by ϵ), the utility of the model is generally very\n",
      "bad, due to the large amount of noise required by dp for\n",
      "a reasonable ϵ budget. indeed, this noise prevents gener-\n",
      "ally the convergence of the model or highly decreases its\n",
      "performances.\n",
      "\n",
      "recent works show that it is possible to improve the\n",
      "utility of a differentially private model by: reducing the\n",
      "sensitivity of the model’s update (s) and/or increasing\n",
      "the value to noise level (kerkouche et al., 2021a,b) or\n",
      "\n",
      "415\n",
      "\n",
      "\f",
      "even by local adaptation yu et al. (2020). note that, the\n",
      "sensitivity s is not the only dp parameter which gov-\n",
      "erns the noise. indeed, reducing the sampling probability\n",
      "c = k/n is also one manner to reduce the noise for\n",
      "a given ϵ budget. however, in certain scenarios as ours\n",
      "when we have only few participants (small n ) with small\n",
      "datasets, the convergence of the model before using dp\n",
      "can be possible only with a large sampling probability (c\n",
      "is set to 0.5 in our case). therefore, noise might be very\n",
      "large in such cases, e.g. the noise multiplier σ is set to\n",
      "σ = 2, 3 which result in ϵ = 5.4, 8.9, respectively.\n",
      "\n",
      "3.2.2. our solution\n",
      "\n",
      "to tackle the well-known ”utility-privacy tradeoff” un-\n",
      "der challenging settings, we propose a straightforward ap-\n",
      "proach called dpfed-post. our scheme outperforms the\n",
      "standard differentially private federated learning scheme\n",
      "(dpfed) by adding one normalization step.\n",
      "\n",
      "indeed, in both dpfed-post and dpfed, at each round\n",
      "r the server sends the global model wr−1 to k clients\n",
      "selected randomly, each selected client trains and sends\n",
      "back its model to the server. the server clips the update\n",
      "to have a l2-norm at most s. after\n",
      "of each client ∆wr\n",
      "k\n",
      "that, the server sums up the clipped updates ∆ ˆwr\n",
      ", adds\n",
      "k\n",
      "the gaussian noise and average it to obtain the noisy\n",
      "update ∆ ˆwr.\n",
      "\n",
      "the difference between dpfed-post and dpfed starts\n",
      "from this step.\n",
      "instead of directly updating the global\n",
      "model with the averaged noisy update as it is the case\n",
      "in dpfed, in our scheme dpfed-post, ∆wr is normalized\n",
      "to obtain ∆ ˆwr with l2-norm at most p . finally, the\n",
      "normalized noisy update ∆ ˆwr is used to update the new\n",
      "global model wr (see alg. 1 for more details).\n",
      "\n",
      "this normalization acts exactly as decreasing the learn-\n",
      "ing rate. indeed, the large additive noise generally pre-\n",
      "vents the convergence to a good local minimum. there-\n",
      "fore, this normalization will slow down the learning pro-\n",
      "cess in order to reach better performances compared to\n",
      "the standard scheme dpfed.\n",
      "\n",
      "3.2.3. privacy analysis:\n",
      "\n",
      "the adversary can only access the noisy model which\n",
      "is sufficiently perturbed to ensure client-level differential\n",
      "privacy; any client-specific information that could be in-\n",
      "ferred from the model is tracked and quantified by the\n",
      "moments accountant, described in section 2.3, as follows.\n",
      "(x) and η1(x|ξ) = (1 −\n",
      "(x) where c is the sam-\n",
      "c)pdf g(0,ξ)\n",
      "pling probability of\n",
      "single\n",
      "single\n",
      "round. let α(λ|c) = log max(e1(λ, ξ, c), e2(λ, ξ, c))\n",
      "where e1(λ, ξ, c) = r\n",
      "r η0(x|ξ, c) ·\n",
      "dx and\n",
      "e2(λ, ξ, c) = r\n",
      "\n",
      "let η0(x|ξ) = pdf g(0,ξ)\n",
      "(x) + cpdf g(1,ξ)\n",
      "\n",
      "(cid:16) η0(x|ξ,c)\n",
      "η1(x|ξ,c)\n",
      "(cid:17)λ\n",
      "\n",
      "r η1(x|ξ, c) ·\n",
      "\n",
      "(cid:16) η1(x|ξ,c)\n",
      "η0(x|ξ,c)\n",
      "\n",
      "client\n",
      "\n",
      "in a\n",
      "\n",
      "dx.\n",
      "\n",
      "(cid:17)λ\n",
      "\n",
      "a\n",
      "\n",
      "theorem 4 (privacy of dpfed-post)\n",
      "(minλ(tcl · α(λ|c) − log δ)/λ, δ)-dp.\n",
      "\n",
      "dpfed-post\n",
      "\n",
      "is\n",
      "\n",
      "given a fixed value of δ, ε is computed numerically as in\n",
      "abadi et al. (2016); mironov et al. (2019).\n",
      "\n",
      "4. experimental results\n",
      "\n",
      "4.1. neural networks for survival analysis\n",
      "\n",
      "in this paper, we utilize 4 deep neural networks which\n",
      "are designed for survival analysis. as explained in sec-\n",
      "tion. 2.2, by defining appropriate loss functions for neural\n",
      "networks, they could be used to serve specific purposes:\n",
      "coxph: adopted from kvamme et al. (2019), also\n",
      "known as deepsurv (katzman et al., 2018) replaces g(x)\n",
      "of equation. 5 with a fully connected deep neural network.\n",
      "the loss for this model is defined as:\n",
      "\n",
      "loss =\n",
      "\n",
      "1\n",
      "\n",
      "n\n",
      "\n",
      "x\n",
      "\n",
      "log\n",
      "\n",
      "x\n",
      "\n",
      "i:ei=1\n",
      "\n",
      "j∈ri\n",
      "\n",
      "!\n",
      "\n",
      "exp[g(xj) − g(xi)]\n",
      "\n",
      "(10)\n",
      "\n",
      "coxcc: adopted from kvamme et al. (2019), similar\n",
      "to coxph except for the fact that the risk set ri of the\n",
      "loss function is approximated with a large enough set to\n",
      "make calculations easier.\n",
      "\n",
      "coxtime: adopted from kvamme et al. (2019), similar\n",
      "model to coxcc, but the proportionality assumption of\n",
      "the cox hazard model is abondoed:\n",
      "\n",
      "h(t|x) = h0(t) exp[g(t, x)]\n",
      "\n",
      "(11)\n",
      "\n",
      "so that g(t, x) uses the time t as another covariate.\n",
      "\n",
      "deephit: adopted from kvamme et al. (2019); lee et al.\n",
      "(2018a), this model is fundamentally different from the\n",
      "previous 3 models and makes no assumption about the\n",
      "underlying relation between the covariates.\n",
      "it has a 2-\n",
      "part loss function; the first part measures the negative\n",
      "log-likelihood and the second part is a ranking loss which\n",
      "investigates each possible pair of data and tries to sort\n",
      "them with respect to their time of event. the output of all\n",
      "the previous models were continuous over time. however,\n",
      "the output of deephit is discretized and we need to define\n",
      "time-bins over the experiment span of our datasets.\n",
      "\n",
      "4.2. metrics\n",
      "\n",
      "in this section we explain 3 different performance met-\n",
      "rics, each offering a unique perspective into measuring\n",
      "how well the models predict on the data (for detailed ex-\n",
      "planation cf. kvamme et al. (2019)).\n",
      "\n",
      "4.2.1. integrated brier score\n",
      "\n",
      "brier score is a performance measure for binary labels and\n",
      "takes into account both the discrimination as well as the\n",
      "\n",
      "416\n",
      "\n",
      " \n",
      "\f",
      "calibration of the model’s predictions. to make our labels\n",
      "- which are times of events - binary, we can pick a fixed\n",
      "time t and binarize based on whether or not the event\n",
      "happens before or after this time t. so the generalized\n",
      "brier score graf et al. (1999) can be calculated as:\n",
      "\n",
      "bs(t) =\n",
      "\n",
      "1\n",
      "\n",
      "n\n",
      "\n",
      "n\n",
      "x\n",
      "\n",
      "i=1\n",
      "\n",
      "h ˆs(t|xi)21(ti ≤ t, ei = 1)\n",
      "ˆg(ti)\n",
      "\n",
      "+\n",
      "\n",
      "(1 − ˆs(t|xi))21(ti > t)\n",
      "ˆg(t)\n",
      "\n",
      "i\n",
      "\n",
      "(12)\n",
      "\n",
      "where n is the number of data points and ˆg(t) is the\n",
      "kaplan-meier estimate for censoring survival function\n",
      "p(t > t) which helps to account also for the censored\n",
      "data in this metric. note that ei = 1 and ei = 0 rep-\n",
      "resent datapoints experiencing the event of interest and\n",
      "censoring, respectively.\n",
      "\n",
      "to further extend the bs(t) to all the possible time\n",
      "\n",
      "values t, we can integrate over time:\n",
      "\n",
      "integrated bs = ibs =\n",
      "\n",
      "1\n",
      "t2 − t1\n",
      "\n",
      "z t2\n",
      "\n",
      "t1\n",
      "\n",
      "bs(s)ds\n",
      "\n",
      "(13)\n",
      "\n",
      "which can be approximated numerically by a time grid\n",
      "over the test set. note that a lower value of the brier score\n",
      "or integrated brier score indicates better performance of\n",
      "the model.\n",
      "\n",
      "4.2.2. integrated binomial log-likelihood\n",
      "\n",
      "this is also another binary classification metric that mea-\n",
      "sures discrimination and calibration. in the same fashion\n",
      "as brier score, we can binarized the labels and define the\n",
      "mean binomial log likelihood as:\n",
      "\n",
      "bll(t) =\n",
      "\n",
      "1\n",
      "\n",
      "n\n",
      "\n",
      "+\n",
      "\n",
      "n\n",
      "x\n",
      "\n",
      "i=1\n",
      "\n",
      "h log(1 − ˆs(t|xi))1(ti ≤ t, ei = 1)\n",
      "ˆg(ti)\n",
      "i\n",
      "\n",
      "log( ˆs(t|xi))1(ti > t)\n",
      "ˆg(t)\n",
      "\n",
      "(14)\n",
      "\n",
      "we can again integrate over different times in the same\n",
      "\n",
      "way as 13:\n",
      "\n",
      "integrated bll = ibll =\n",
      "\n",
      "1\n",
      "t2 − t1\n",
      "\n",
      "z t2\n",
      "\n",
      "t1\n",
      "\n",
      "bll(s)ds\n",
      "\n",
      "(15)\n",
      "\n",
      "a higher value of the integrated binomial log-likelihood\n",
      "indicates better performance of the model. to avoid re-\n",
      "porting negative values, in our experiments we calculate\n",
      "the negative integrated binomial log-likelihood, so here,\n",
      "lower values are preferred.\n",
      "\n",
      "4.2.3. concordance index\n",
      "\n",
      "concordance index (c-index) harrell et al. (1982) is one\n",
      "of the most commonly-used metrics in the field of sur-\n",
      "vival analysis. the concordance is only concerned with\n",
      "the ordering of the pairs of data points in the data set,\n",
      "regardless of the true time of the events.\n",
      "the time-dependent c-index, for a pair of data points i\n",
      "and j can be estimated by:\n",
      "\n",
      "c-index = p{ ˆf (ti|xi) > ˆf (ti|xj)|ti < tj, ei = 1}\n",
      "\n",
      "≈\n",
      "\n",
      "p\n",
      "\n",
      "i̸=j ai,j1( ˆf (ti|xi) > ˆf (ti|xj))\n",
      "i̸=j ai,j\n",
      "\n",
      "p\n",
      "\n",
      "(16)\n",
      "\n",
      "where ˆf (t|x) is the estimated cif and ai,j is a sorting\n",
      "function defined as ai,j = 1(ti < tj, ei = 1). the idea is\n",
      "that when comparing two data points, if one experiences\n",
      "the event sooner than the other, at that event time, it\n",
      "should have a lower survival probability than the other\n",
      "data point. a c-index of 0.5 indicates chance-level pre-\n",
      "diction and higher values indicate better performance.\n",
      "\n",
      "4.3. datasets\n",
      "\n",
      "for our experiments, we choose three real-world medical\n",
      "datasets which are collected over multiple years:\n",
      "\n",
      "rotterdam and german breast cancer study group\n",
      "(gbsg): contains data of 2232 breast cancer patients\n",
      "from the rotterdam tumor bank foekens et al. (2000) and\n",
      "the german breast cancer study group (gbsg) schu-\n",
      "macher et al. (1994). the data is pre-processed similar\n",
      "to katzman et al. (2018) and contains 7 features and the\n",
      "maximum survival duration is 87 months.\n",
      "\n",
      "the molecular taxonomy of breast cancer interna-\n",
      "tional consortium (metabric): this dataset contains\n",
      "gene and protein expressions of 1904 individuals curtis\n",
      "et al. (2012). we use a dataset prepared similar to katz-\n",
      "man et al. (2018). this pre-processed dataset contains 4\n",
      "gene indicators (mki67, egfr, pgr, and erbb2) and\n",
      "5 clinical features (hormone treatment indicator, radio-\n",
      "therapy indicator, chemotherapy indicator, er-positive\n",
      "indicator, age at diagnosis) for each patient and is fol-\n",
      "lowed for a maximum of 355 months.\n",
      "\n",
      "study to understand prognoses preferences outcomes\n",
      "and risks of treatment (support): this dataset con-\n",
      "sists of 8873 seriously-ill adults knaus et al. (1995). the\n",
      "dataset has 14 features (age, sex, race, number of comor-\n",
      "bidities, presence of diabetes, presence of dementia, pres-\n",
      "ence of cancer, mean arterial blood pressure, heart rate,\n",
      "respiration rate, temperature, white blood cell count,\n",
      "serum’s sodium, and serum’s creatinine) with a maximum\n",
      "survival time of 67 months. we use a pre-processed ver-\n",
      "sion according to katzman et al. (2018).\n",
      "\n",
      "data in practice: for all our experiments, we assume\n",
      "that 10 hospitals/data centers would like to collaborate to\n",
      "\n",
      "417\n",
      "\n",
      "\f",
      "train a model. this is a reasonable estimate of the num-\n",
      "ber of health centers that would like to study a specific\n",
      "disease, as seen e.g.\n",
      "in tomczak et al. (2015); murphy\n",
      "et al. (2000); linge et al. (2016). furthermore, in prac-\n",
      "tice, each hospital would have access to only a few hun-\n",
      "dred data (e.g. mohan et al., 1996; gy¨orffy et al., 2010;\n",
      "chi et al., 2007). in table 1, we show for each dataset\n",
      "how many patients were censorded, and given that the\n",
      "data is split between 10 hospital, how many patients each\n",
      "hospital would have.\n",
      "\n",
      "4.4. setup\n",
      "\n",
      "in this section, we give an overview of the technical details\n",
      "of our experiments in both centralized and federated set-\n",
      "ting. as mentioned in section 4.1, the output of all the\n",
      "models except deephit are continuous. for this reason\n",
      "we define time-bins with duration of ∼ 12 months for all\n",
      "of our datasets when deploying deephit. we use pycox\n",
      "package 2 to construct all our models.\n",
      "\n",
      "centralized: to have a baseline to compare the effect of\n",
      "federation of the models, we first need to study their per-\n",
      "formance in a centralized setting. datasets are randomly\n",
      "split into 80% training and 20% test data. to account for\n",
      "the effect of this random splitting, we run each experiment\n",
      "5 times and report the average value and standard devia-\n",
      "tion. for all our experiments, the structure of all models\n",
      "are in the form of [input, 32, 32, output] fully-connected\n",
      "nodes. we use adamoptimizer with a learning rate of\n",
      "10−4 to train these models and use an early stopping cri-\n",
      "terion to achieve the best performance.\n",
      "\n",
      "federated: for all of the federated experiments, we\n",
      "again randomly split the data into 80% training and 20%\n",
      "test set. the training set is then randomly split into n =\n",
      "10 equal-sized parts to be assigned to each client. here, we\n",
      "also run the experiments 5 times with different random\n",
      "splittings and report the average performance and the\n",
      "standard deviation.\n",
      "\n",
      "the same neural network structure and optimizer as\n",
      "the centralized setting is used by clients. at each round\n",
      "of communication, the selected clients train their model\n",
      "for 50 local epochs. the training is done for a total of\n",
      "tcl = 50 communication rounds.\n",
      "\n",
      "we start our experiments in a centralized settings. in\n",
      "the second stage, we study the effect of standard fed-\n",
      "eration (stdfed, algorithm. 2 in appendix a) with no\n",
      "privacy protocol, on the performance of the model. we\n",
      "then apply client-level differential privacy (dpfed, algo-\n",
      "rithm. 3 in appendix a) to this federated scheme. finally,\n",
      "we utilize our post-processing solution (dpfed-post, al-\n",
      "gorithm. 1) on top of the client-level dp federated learn-\n",
      "ing pipeline.\n",
      "\n",
      "centralized to stdfed: the first step of our experi-\n",
      "ments is to study the effect of federation of deep sur-\n",
      "\n",
      "2. https://github.com/havakv/pycox\n",
      "\n",
      "vival models over 10 hospitals. to pick a suitable client\n",
      "sampling probability c, we ran our experiments for c =\n",
      "{0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0} and chose the\n",
      "lowest value that results in a comparable performance of\n",
      "the federated model after 50 rounds and the centralized\n",
      "setting. we pick the lowest acceptable c since later when\n",
      "dp is applied, the lower value of client sampling proba-\n",
      "bility would lead to better privacy guarantees.\n",
      "\n",
      "stdfed to dpfed: many hyper-parameters play a role\n",
      "when applying dp on federated learning algorithm. the\n",
      "parameter update clipping threshold s, the gaussian\n",
      "noise multiplier σ, the client sampling probability c, to-\n",
      "tal number of communication rounds tcl, and δ effect the\n",
      "performance of the model as well as the calculated privacy\n",
      "budget ϵ (see theorem. 4 and algorithm 1).\n",
      "\n",
      "the parameter δ is usually set to the inverse of the size\n",
      "of the population that the privacy mechanism is applied\n",
      "on, here 10 clients. however, δ = 10−1, which represents\n",
      "the probability of dp being broken, is too large for any\n",
      "tight theoretical guarantee. therefore, we set δ = 10−3\n",
      "for all our calculations.\n",
      "\n",
      "we also fix the number of communication rounds to\n",
      "tcl = 50 since in the case of stdfed this seems to be\n",
      "enough for all the models and datasets to achieve compa-\n",
      "rable performance to the centralized setting.\n",
      "\n",
      "when choosing the client sampling probability c, we\n",
      "face a privacy/utility trade-off: the higher the sampling\n",
      "probability, the better the utility of the final model and\n",
      "the higher the value of the privacy budget ϵ. we choose\n",
      "c = 0.5 as it is the lowest value that results in comparable\n",
      "utility between the stdfed and centralized models.\n",
      "\n",
      "the sensitivity s is chosen during the initialization pe-\n",
      "riod in collaboration with all the participants. we pick\n",
      "the median value of the clients updates as our clipping\n",
      "threshold s.\n",
      "\n",
      "the noise multiplier σ has a significant impact on the\n",
      "performance of the models as well the calculated privacy\n",
      "budget ϵ and there is a trade-off between these two: the\n",
      "tighter the privacy guarantee, the worse the utility of the\n",
      "model. hence we are looking for a reasonable operation\n",
      "point where there is a balance between the value of ϵ and\n",
      "utility. we pick two different values of σ = 2, 3 which\n",
      "result in ϵ = 5.4, 8.9, respectively 3.\n",
      "\n",
      "dpfed to dpfed-post: when applying the post-\n",
      "processing step on the client-level dp (dpfed-post al-\n",
      "gorithm 1), the value of parameter p also needs to be\n",
      "fixed. this parameter represents the clipping threshold\n",
      "for the average update vector. to find a suitable p value,\n",
      "we examined p = {1s, 2s, 3s, 4s, 5s} where s is the pa-\n",
      "rameter update clipping threshold from the previous step.\n",
      "a choice of 2s or 3s gave consistent improvement across\n",
      "all investigated models and datsets.\n",
      "\n",
      "3. given a fixed value of δ, ε is computed numerically as in\n",
      "abadi et al. (2016); mironov et al. (2019). (see section 4\n",
      "for more details.\n",
      "\n",
      "418\n",
      "\n",
      "\f",
      "table 1: details of each datasets\n",
      "\n",
      "dataset\n",
      "gbsg\n",
      "metabric\n",
      "support\n",
      "\n",
      "# features #uncensored #censored #hospitals # training data/hospital\n",
      "\n",
      "7\n",
      "9\n",
      "14\n",
      "\n",
      "1272(57%)\n",
      "1103(58%)\n",
      "6034(68%)\n",
      "\n",
      "960(43%)\n",
      "801(42%)\n",
      "2839(32%)\n",
      "\n",
      "10\n",
      "10\n",
      "10\n",
      "\n",
      "178\n",
      "152\n",
      "709\n",
      "\n",
      "table 2: gbsg dataset\n",
      "\n",
      "metric\n",
      "\n",
      "c-index\n",
      "↑\n",
      "\n",
      "ibs\n",
      "↓\n",
      "\n",
      "nibll\n",
      "↓\n",
      "\n",
      "model\n",
      "deephit\n",
      "coxph\n",
      "coxcc\n",
      "coxtime\n",
      "deephit\n",
      "coxph\n",
      "coxcc\n",
      "coxtime\n",
      "deephit\n",
      "coxph\n",
      "coxcc\n",
      "coxtime\n",
      "\n",
      "non-private\n",
      "\n",
      "(ϵ = 5.4, δ = 10−3)\n",
      "\n",
      "(ϵ = 8.9, δ = 10−3)\n",
      "\n",
      "centralized\n",
      "0.66 ± 0.02\n",
      "0.66 ± 0.01\n",
      "0.63 ± 0.02\n",
      "0.64 ± 0.01\n",
      "0.18 ± 0.01\n",
      "0.18 ± 0.01\n",
      "0.19 ± 0.01\n",
      "0.18 ± 0.01\n",
      "0.54 ± 0.01\n",
      "0.53 ± 0.01\n",
      "0.56 ± 0.02\n",
      "0.54 ± 0.01\n",
      "\n",
      "stdfed\n",
      "0.67 ± 0.02\n",
      "0.67 ± 0.03\n",
      "0.68 ± 0.01\n",
      "0.67 ± 0.01\n",
      "0.21 ± 0.01\n",
      "0.18 ± 0.01\n",
      "0.18 ± 0.01\n",
      "0.18 ± 0.01\n",
      "0.62 ± 0.03\n",
      "0.53 ± 0.01\n",
      "0.52 ± 0.01\n",
      "0.52 ± 0.01\n",
      "\n",
      "dpfed\n",
      "0.47 ± 0.03\n",
      "0.45 ± 0.70\n",
      "0.58 ± 0.05\n",
      "0.57 ± 0.07\n",
      "0.29 ± 0.05\n",
      "0.36 ± 0.08\n",
      "0.30 ± 0.06\n",
      "0.26 ± 0.05\n",
      "1.73 ± 0.80\n",
      "1.70 ± 0.90\n",
      "1.69 ± 0.90\n",
      "0.87 ± 0.22\n",
      "\n",
      "dpfedpost\n",
      "0.56 ± 0.04\n",
      "0.62 ± 0.02\n",
      "0.61 ± 0.02\n",
      "0.62 ± 0.02\n",
      "0.20 ± 0.01\n",
      "0.20 ± 0.01\n",
      "0.19 ± 0.01\n",
      "0.19 ± 0.01\n",
      "0.57 ± 0.01\n",
      "0.56 ± 0.02\n",
      "0.56 ± 0.01\n",
      "0.56 ± 0.02\n",
      "\n",
      "dpfed\n",
      "0.54 ± 0.03\n",
      "0.47 ± 0.05\n",
      "0.62 ± 0.02\n",
      "0.61 ± 0.03\n",
      "0.21 ± 0.01\n",
      "0.29 ± 0.08\n",
      "0.20 ± 0.01\n",
      "0.20 ± 0.01\n",
      "0.63 ± 0.06\n",
      "1.51 ± 0.90\n",
      "0.59 ± 0.03\n",
      "0.57 ± 0.01\n",
      "\n",
      "dpfedpost\n",
      "0.59 ± 0.03\n",
      "0.64 ± 0.03\n",
      "0.64 ± 0.03\n",
      "0.63 ± 0.02\n",
      "0.19 ± 0.01\n",
      "0.19 ± 0.01\n",
      "0.18 ± 0.01\n",
      "0.19 ± 0.01\n",
      "0.56 ± 0.01\n",
      "0.55 ± 0.03\n",
      "0.54 ± 0.01\n",
      "0.55 ± 0.01\n",
      "\n",
      "4.5. observations\n",
      "\n",
      "the results per dataset are shown in tables .2 (and .4,\n",
      ".5 in appendix b). the non-private column contains the\n",
      "results for centralized setting and federated training of\n",
      "the model using the standard fedavg algorithm. 2. the\n",
      "two other columns each compare the results when regular\n",
      "differentially-private federated learning is used to when\n",
      "our post-processing technique is applied, for each privacy\n",
      "regime. the standard deviations are reported over 5 ran-\n",
      "dom splits of the data as explained in section. 4.4. the\n",
      "arrows next to metrics indicate if a lower or a higher value\n",
      "is desired.\n",
      "\n",
      "the first observation is that the average performance\n",
      "of standard federated training of these survival models\n",
      "is always at a comparable level to the centralized setting.\n",
      "this is an important finding, showing that with federation\n",
      "of small datasets, over only 50 rounds of communication,\n",
      "acceptable utilities can be achieved.\n",
      "\n",
      "investigating the effect of post-processing technique: to\n",
      "be able to assess how well our proposed technique works,\n",
      "for each privacy regime we compare the performance of\n",
      "dpfed-post with dpfed. the bold numbers in the tables\n",
      "indicate a better relative utility for our method. we ob-\n",
      "serve that for most of the models and metrics and datasets\n",
      "our technique results in an improved performance.\n",
      "in\n",
      "particular for gbsg dataset, we always see an improve-\n",
      "ment. from table. 1 we see that gbsg has the second\n",
      "most number of data points and the least number of fea-\n",
      "tures. so this finding might be related to the fact that\n",
      "it is easier for models to converge for this dataset and\n",
      "\n",
      "post-processing always helps in leading the gradient in\n",
      "the right direction.\n",
      "\n",
      "to be able to measure the change in performance quan-\n",
      "\n",
      "titatively, we define\n",
      "\n",
      "∆a→b = ±\n",
      "\n",
      "[metric(b) − metric(a)]\n",
      "metric(a)\n",
      "\n",
      "(17)\n",
      "\n",
      "which measures the improvement of strategy b w.r.t\n",
      "strategy a. for ibs and nibll a negative value of\n",
      "[metric(b)−metric(a)] and for c-index a positive value of\n",
      "this parameter shows improvement. so we also multiply\n",
      "by −1 when calculating for ibs and nibll.\n",
      "\n",
      "the average values of ∆dpfed→dpfed-post for each ϵ\n",
      "value are shown in table. 3. we calculate ∆ according\n",
      "to equation. 17 for each dataset and metric and model\n",
      "and report the average over all of them. for both values\n",
      "of privacy budget, we observe an average improvement of\n",
      "performance when the post-processing step is applied: for\n",
      "ϵ = 5.4 post-processing results in 17% improvement and\n",
      "for ϵ = 8.9 the average performance is improved by 12%.\n",
      "post-processing helps more for the case of ϵ = 5.4 and this\n",
      "is expected since at lower ϵ values more dp noise is ap-\n",
      "plied to the model and the convergence of the model with\n",
      "no regularization of the learning rate (via post-processing)\n",
      "becomes difficult and the final model shows noisy behav-\n",
      "ior.\n",
      "\n",
      "to study the effect of post-processing on reducing the\n",
      "standard deviations, we calculate the average relative\n",
      "standard deviation rstd = (std/mean) across all datasets\n",
      "and models and all metrics. the change of this value\n",
      "\n",
      "419\n",
      "\n",
      "\f",
      "from dpfed to dpfed-post is shown in the second row\n",
      "of table. 3. for both values of ϵ, post-processing helps to\n",
      "reduce the average relative standard deviation. we ob-\n",
      "serve that rstdavg for dpfed is much larger for ϵ = 5.4\n",
      "compared to ϵ = 8.9. this is expected since, the noise\n",
      "added to the model is larger in the case of ϵ = 5.4 and\n",
      "this results in the final model showing different behaviors\n",
      "after each round of running the experiments.\n",
      "interest-\n",
      "ingly, rstdavg retains a value of 0.05 for both ϵ regimes.\n",
      "this indicates that our method is successful in suppress-\n",
      "ing large deviations of the model even for higher noise\n",
      "values.\n",
      "\n",
      "5. related work\n",
      "\n",
      "cox proportional hazards model cox (1972) is one of the\n",
      "earliest and most powerful models for survival analysis.\n",
      "however, it makes very restrictive assumptions on the the\n",
      "data, such as linear dependence of the covariates and pro-\n",
      "portionality of the hazard rate over time. there has been\n",
      "some suggested modifications to this formulations, such\n",
      "as time-dependent variables andersen and gill (1982);\n",
      "fisher and lin (1999) or assuming a wiener process lee\n",
      "and whitmore (2010).\n",
      "\n",
      "faraggi and simon (1995) were the first to use simple\n",
      "perceptron model for cox regression. in 2018 katzman\n",
      "et al. (2018) proposed deepsurv, a deep neural network\n",
      "for cox regression, and showed that their model outper-\n",
      "forms a simple cox proportional hazards model. kvamme\n",
      "et al. (2019) proposed coxtime, a modification of deep-\n",
      "surv, with no proportionality assumption on the data.\n",
      "in a slightly different direction, lee et al. (2018a) used a\n",
      "deep neural network with no assumption on the data to\n",
      "learn the survival functions.\n",
      "\n",
      "due to the high sensitivity of the medical data which\n",
      "are used for the survival analysis, hospitals are often re-\n",
      "luctant to share and centralize them. fortunately, fed-\n",
      "erated learning allows different clients to train collab-\n",
      "oratively a common model without sharing their data.\n",
      "federated learning first proposed by google mcmahan\n",
      "et al. (2017); koneˇcn`y et al. (2016) has recently become\n",
      "very popular as a method of distributed training of ma-\n",
      "chine learning models. it has been used for mobile key-\n",
      "board prediction hard et al. (2018); lim et al. (2020),\n",
      "financial fraud detection suzumura et al. (2019); yang\n",
      "et al. (2019) and in healthcare for, e.g. patient similar-\n",
      "ity learning lee et al. (2018b) and patient representation\n",
      "learning liu et al. (2019); kim et al. (2017).\n",
      "\n",
      "although, federated learning is more privacy-\n",
      "preserving compared to its centralized counterpart, dif-\n",
      "ferent attacks show that the adversary can still\n",
      "infer\n",
      "sensitive information by only using the model’s param-\n",
      "eters/updates.\n",
      "indeed, nasr et al. (2019); melis et al.\n",
      "(2019) define a membership attack that allows to infer if\n",
      "a particular sample is included in the dataset of a spe-\n",
      "\n",
      "cific client. similarly, melis et al. (2019) define an attack\n",
      "which aims at inferring if a group of people with a spe-\n",
      "cific property, like for example skin color or ethnicity, is\n",
      "included in the dataset of a particular participating en-\n",
      "tity. finally, the strongest attack is called reconstruction\n",
      "attack zhu et al. (2019); zhao et al. (2020); geiping et al.\n",
      "(2020) presented some attacks that allow an adversary to\n",
      "reconstruct some training data samples of some entities.\n",
      "a solution to prevent these attacks and provide theoreti-\n",
      "cal guarantees in to use a privacy model called differential\n",
      "privacy (dwork and roth, 2014).\n",
      "\n",
      "kerkouche et al. (2021c) uses record-level differential\n",
      "privacy to protect the federated training of medical data.\n",
      "in kerkouche et al. (2021b,a) client-level differential pri-\n",
      "vacy has been used to protect medical data of each hos-\n",
      "pital in a federated setting. in their work, they are con-\n",
      "cerned with a binary classifier that predicts if a patient\n",
      "would die. they address the problem of instability of\n",
      "training after adding noise by reducing the sensitivity s\n",
      "and increasing the value-to-noise levels, either by using\n",
      "compressive sensing kerkouche et al. (2021a) or by con-\n",
      "straining the model kerkouche et al. (2021b).\n",
      "\n",
      "as far as we know, our work is the first which investi-\n",
      "gates the utility-privacy tradeoff introduced by dp under\n",
      "such challenging but realistic settings for the privacy anal-\n",
      "ysis. indeed, we consider a scenario with a total of only\n",
      "10 hospitals and where half of them participate at each\n",
      "round. this means that our sampling probability c is set\n",
      "to 0.5 and the additive noise required by dp is also very\n",
      "large.\n",
      "\n",
      "6. conclusion\n",
      "\n",
      "in this work, we tackle the challenge of using small\n",
      "datasets to train a differentially-private model in a fed-\n",
      "erated setting. this becomes relevant when the collec-\n",
      "tion of data is time-consuming and expensive, and only\n",
      "a few specialized data holders are interested in training a\n",
      "model. we propose adding a post-processing step to the\n",
      "popular client-level differentially private federated learn-\n",
      "ing scheme. our results indicate that this technique -\n",
      "which we refer to as dpfed-post - consistently improves\n",
      "the performances of the models and reduces the disparity\n",
      "in its behavior.\n",
      "\n",
      "institutional review board (irb)\n",
      "\n",
      "this research is based on publicly available datasets and\n",
      "does not require irb approval.\n",
      "\n",
      "420\n",
      "\n",
      "\f",
      "table 3: quantitative comparison of the performance of dpfed and dpfed-post. the values are averaged\n",
      "\n",
      "over all datasets and all metrics and all models.\n",
      "\n",
      "(ϵ = 5.4, δ = 10−3)\n",
      "dpfed→dpfed-post dpfed → dpfed-post\n",
      "\n",
      "(ϵ = 8.9, δ = 10−3)\n",
      "\n",
      "∆avg\n",
      "rstdavg\n",
      "\n",
      "0.17\n",
      "0.19 → 0.05\n",
      "\n",
      "0.12\n",
      "0.07 → 0.05\n",
      "\n",
      "7. acknowledgments\n",
      "\n",
      "this work is partially funded by the helmholtz associa-\n",
      "tion within the project “trustworthy federated data an-\n",
      "alytics” (tfda) (funding number zt-i-oo1 4).\n",
      "\n",
      "references\n",
      "\n",
      "martin abadi, andy chu, ian goodfellow, h. brendan\n",
      "mcmahan, ilya mironov, kunal talwar, and li zhang.\n",
      "deep learning with differential privacy. in acm ccs,\n",
      "2016.\n",
      "\n",
      "per kragh andersen and richard d gill. cox’s regression\n",
      "model for counting processes: a large sample study. the\n",
      "annals of statistics, pages 1100–1120, 1982.\n",
      "\n",
      "sean augenstein, h brendan mcmahan, daniel ramage,\n",
      "swaroop ramaswamy, peter kairouz, mingqing chen,\n",
      "rajiv mathews, et al. generative models for effective\n",
      "ml on private, decentralized datasets. arxiv preprint\n",
      "arxiv:1911.06679, 2019.\n",
      "\n",
      "bart baesens, tony van gestel, maria stepanova, dirk\n",
      "van den poel, and jan vanthienen. neural network\n",
      "survival analysis for personal loan data. journal of the\n",
      "operational research society, 56(9):1089–1098, 2005.\n",
      "\n",
      "hermann brenner. long-term survival rates of cancer pa-\n",
      "tients achieved by the end of the 20th century: a period\n",
      "analysis. the lancet, 360(9340):1131–1135, 2002.\n",
      "\n",
      "liberato camilleri. history of survival analysis, 2019.\n",
      "url https://www.um.edu.mt/library/oar/handle/\n",
      "123456789/55748.\n",
      "\n",
      "chih-lin chi, w nick street, and william h wolberg.\n",
      "application of artificial neural network-based survival\n",
      "analysis on two breast cancer datasets. in amia an-\n",
      "nual symposium proceedings, volume 2007, page 130.\n",
      "american medical informatics association, 2007.\n",
      "\n",
      "david r cox. regression models and life-tables. journal\n",
      "of the royal statistical society: series b (methodolog-\n",
      "ical), 34(2):187–202, 1972.\n",
      "\n",
      "christina curtis, sohrab p shah, suet-feung chin,\n",
      "gulisa turashvili, oscar m rueda, mark j dunning,\n",
      "doug speed, andy g lynch, shamith samarajiwa,\n",
      "yinyin yuan, et al. the genomic and transcriptomic\n",
      "architecture of 2,000 breast tumours reveals novel sub-\n",
      "groups. nature, 486(7403):346–352, 2012.\n",
      "\n",
      "lore dirick, gerda claeskens, and bart baesens. time\n",
      "to default in credit scoring using survival analysis: a\n",
      "benchmark study. journal of the operational research\n",
      "society, 68(6):652–665, 2017.\n",
      "\n",
      "cynthia dwork and aaron roth. the algorithmic foun-\n",
      "dations of differential privacy. foundations and trends\n",
      "in theoretical computer science, 9(3–4), 2014.\n",
      "\n",
      "david faraggi and richard simon. a neural network\n",
      "model for survival data. statistics in medicine, 14(1):\n",
      "73–82, 1995.\n",
      "\n",
      "lloyd d fisher and danyu y lin. time-dependent covari-\n",
      "ates in the cox proportional-hazards regression model.\n",
      "annual review of public health, 20(1):145–157, 1999.\n",
      "\n",
      "john a foekens, harry a peters, maxime p look, henk\n",
      "portengen, manfred schmitt, michael d kramer, nils\n",
      "br¨unner, fritz j¨anicke, marion e meijer-van gelder,\n",
      "sonja c henzen-logmans, et al. the urokinase system\n",
      "of plasminogen activation and prognosis in 2780 breast\n",
      "cancer patients. cancer research, 60(3):636–643, 2000.\n",
      "\n",
      "jonas geiping, hartmut bauermeister, hannah dr¨oge,\n",
      "and michael moeller. inverting gradients-how easy is\n",
      "it to break privacy in federated learning? advances\n",
      "in neural information processing systems, 33:16937–\n",
      "16947, 2020.\n",
      "\n",
      "robin c geyer, tassilo klein, and moin nabi. differen-\n",
      "tially private federated learning: a client level perspec-\n",
      "tive. arxiv preprint arxiv:1712.07557, 2017.\n",
      "\n",
      "arrpa goldhirsch, richard d gelber, r john simes,\n",
      "paul glasziou, and alan s coates. costs and benefits of\n",
      "adjuvant therapy in breast cancer: a quality-adjusted\n",
      "survival analysis. journal of clinical oncology, 7(1):\n",
      "36–44, 1989.\n",
      "\n",
      "421\n",
      "\n",
      "\f",
      "erika graf, claudia schmoor, willi sauerbrei, and mar-\n",
      "tin schumacher. assessment and comparison of prog-\n",
      "nostic classification schemes for survival data. statistics\n",
      "in medicine, 18(17-18):2529–2545, 1999.\n",
      "\n",
      "balazs gy¨orffy, andras lanczky, aron c eklund, carsten\n",
      "denkert, jan budczies, qiyuan li, and zoltan szallasi.\n",
      "an online survival analysis tool to rapidly assess the\n",
      "effect of 22,277 genes on breast cancer prognosis us-\n",
      "ing microarray data of 1,809 patients. breast cancer\n",
      "research and treatment, 123(3):725–731, 2010.\n",
      "\n",
      "daniel herbert hanson. artificial neural network based\n",
      "survival analysis for hydro-mechanical systems. the\n",
      "university of iowa, 2004.\n",
      "\n",
      "andrew hard, kanishka rao, rajiv mathews, swa-\n",
      "roop ramaswamy, fran¸coise beaufays, sean augen-\n",
      "stein, hubert eichner, chlo´e kiddon, and daniel ram-\n",
      "age. federated learning for mobile keyboard prediction.\n",
      "arxiv preprint arxiv:1811.03604, 2018.\n",
      "\n",
      "frank e harrell, robert m califf, david b pryor, kerry l\n",
      "lee, and robert a rosati. evaluating the yield of med-\n",
      "ical tests. jama, 247(18):2543–2546, 1982.\n",
      "\n",
      "peter kairouz, h brendan mcmahan, brendan avent,\n",
      "aur´elien bellet, mehdi bennis, arjun nitin bhagoji,\n",
      "kallista bonawitz, zachary charles, graham cor-\n",
      "mode, rachel cummings, et al.\n",
      "advances and\n",
      "open problems in federated learning. arxiv preprint\n",
      "arxiv:1912.04977, 2019.\n",
      "\n",
      "jared l katzman, uri shaham, alexander cloninger,\n",
      "jonathan bates, tingting jiang, and yuval kluger.\n",
      "deepsurv: personalized treatment recommender sys-\n",
      "tem using a cox proportional hazards deep neural net-\n",
      "work. bmc medical research methodology, 18(1):1–12,\n",
      "2018.\n",
      "\n",
      "raouf kerkouche, gergely ´acs, claude castelluccia, and\n",
      "pierre genev`es. compression boosts differentially pri-\n",
      "vate federated learning. in 2021 ieee european sym-\n",
      "posium on security and privacy (euros&p), pages\n",
      "304–318. ieee, 2021a.\n",
      "\n",
      "raouf kerkouche, gergely ´acs, claude castelluccia, and\n",
      "pierre genev`es. constrained differentially private fed-\n",
      "erated learning for low-bandwidth devices.\n",
      "in un-\n",
      "certainty in artificial intelligence, pages 1756–1765.\n",
      "pmlr, 2021b.\n",
      "\n",
      "raouf kerkouche, gergely acs, claude castelluccia, and\n",
      "pierre genev`es. privacy-preserving and bandwidth-\n",
      "an application to in-\n",
      "efficient federated learning:\n",
      "in proceedings of the\n",
      "hospital mortality prediction.\n",
      "conference on health, inference, and learning, pages\n",
      "25–35, 2021c.\n",
      "\n",
      "jack kiefer and jacob wolfowitz. stochastic estimation\n",
      "of the maximum of a regression function. the annals\n",
      "of mathematical statistics, pages 462–466, 1952.\n",
      "\n",
      "yejin kim, jimeng sun, hwanjo yu, and xiaoqian jiang.\n",
      "federated tensor factorization for computational phe-\n",
      "notyping.\n",
      "in proceedings of the 23rd acm sigkdd\n",
      "international conference on knowledge discovery and\n",
      "data mining, pages 887–895, 2017.\n",
      "\n",
      "william a knaus, frank e harrell, joanne lynn, lee\n",
      "goldman, russell s phillips, alfred f connors, neal v\n",
      "dawson, william j fulkerson, robert m califf, nor-\n",
      "man desbiens, et al. the support prognostic model:\n",
      "objective estimates of survival for seriously ill hospi-\n",
      "talized adults. annals of internal medicine, 122(3):\n",
      "191–203, 1995.\n",
      "\n",
      "jakub koneˇcn`y, h brendan mcmahan, felix x yu, peter\n",
      "richt´arik, ananda theertha suresh, and dave bacon.\n",
      "federated learning: strategies for improving commu-\n",
      "nication efficiency. arxiv preprint arxiv:1610.05492,\n",
      "2016.\n",
      "\n",
      "h˚avard kvamme, ørnulf borgan, and ida scheel. time-\n",
      "to-event prediction with neural networks and cox re-\n",
      "gression. arxiv preprint arxiv:1907.00825, 2019.\n",
      "\n",
      "erkki k laitinen. survival analysis and financial distress\n",
      "prediction: finnish evidence. review of accounting and\n",
      "finance, 2005.\n",
      "\n",
      "changhee lee, william zame, jinsung yoon, and mihaela\n",
      "van der schaar. deephit: a deep learning approach to\n",
      "survival analysis with competing risks. in proceedings\n",
      "of the aaai conference on artificial intelligence, vol-\n",
      "ume 32, 2018a.\n",
      "\n",
      "eunjo lee, yoonjae jang, du-mim yoon, jihoon jeon,\n",
      "seong-il yang, sang-kwang lee, dae-wook kim,\n",
      "pei pei chen, anna guitart, paul bertens, ´africa\n",
      "peri´a˜nez, fabian hadiji, marc m¨uller, youngjun joo,\n",
      "jiyeon lee, inchon hwang, and kyung-joong kim.\n",
      "game data mining competition on churn prediction\n",
      "and survival analysis using commercial game log data.\n",
      "ieee transactions on games, 11(3):215–226, 2019.\n",
      "doi: 10.1109/tg.2018.2888863.\n",
      "\n",
      "junghye lee, jimeng sun, fei wang, shuang wang, chi-\n",
      "hyuck jun, and xiaoqian jiang. privacy-preserving\n",
      "patient similarity learning in a federated environment:\n",
      "development and analysis. jmir medical informatics,\n",
      "6(2):e20, 2018b.\n",
      "\n",
      "mei-ling ting lee and ga whitmore. proportional haz-\n",
      "their theoretical and\n",
      "ards and threshold regression:\n",
      "practical connections. lifetime data analysis, 16(2):\n",
      "196–214, 2010.\n",
      "\n",
      "422\n",
      "\n",
      "\f",
      "wei yang bryan lim, nguyen cong luong, dinh thai\n",
      "hoang, yutao jiao, ying-chang liang, qiang yang,\n",
      "dusit niyato, and chunyan miao. federated learn-\n",
      "ing in mobile edge networks: a comprehensive sur-\n",
      "vey.\n",
      "ieee communications surveys & tutorials, 22\n",
      "(3):2031–2063, 2020.\n",
      "\n",
      "annett linge, fabian lohaus, steffen l¨ock, alexander\n",
      "nowak, volker gudziol, chiara valentini, cl¨are von\n",
      "neubeck, martin j¨utz, inge tinhofer, volker budach,\n",
      "et al. hpv status, cancer stem cell marker expression,\n",
      "hypoxia gene signatures and tumour volume identify\n",
      "good prognosis subgroups in patients with hnscc after\n",
      "primary radiochemotherapy: a multicentre retrospec-\n",
      "tive study of the german cancer consortium radiation\n",
      "oncology group (dktk-rog). radiotherapy and oncol-\n",
      "ogy, 121(3):364–373, 2016.\n",
      "\n",
      "dianbo liu, dmitriy dligach, and timothy miller. two-\n",
      "stage federated phenotyping and patient representation\n",
      "learning. in proceedings of the conference. association\n",
      "for computational linguistics. meeting, volume 2019,\n",
      "page 283. nih public access, 2019.\n",
      "\n",
      "junxiang lu. predicting customer churn in the telecom-\n",
      "munications industry—-an application of survival anal-\n",
      "ysis modeling using sas. in sas user group interna-\n",
      "tional (sugi27) online proceedings, volume 114, 2002.\n",
      "\n",
      "brendan mcmahan, eider moore, daniel ramage, seth\n",
      "hampson, and blaise aguera y arcas. communication-\n",
      "efficient learning of deep networks from decentralized\n",
      "in artificial intelligence and statistics, pages\n",
      "data.\n",
      "1273–1282. pmlr, 2017.\n",
      "\n",
      "luca melis, congzheng song, emiliano de cristofaro,\n",
      "and vitaly shmatikov. exploiting unintended feature\n",
      "leakage in collaborative learning. in 2019 ieee sym-\n",
      "posium on security and privacy (sp), pages 691–706.\n",
      "ieee, 2019.\n",
      "\n",
      "ilya mironov, kunal talwar, and li zhang. renyi dif-\n",
      "ferential privacy of the sampled gaussian mechanism.\n",
      "arxiv preprint arxiv:1908.10530, 2019.\n",
      "\n",
      "b mishachandar and k anil kumar. predicting customer\n",
      "churn using targeted proactive retention. international\n",
      "journal of engineering & technology, 7(2.27):69, 2018.\n",
      "\n",
      "viswanathan mohan, gopal premalatha, audinarayanan\n",
      "padma, suresh t chari, and capecomorin s pitchu-\n",
      "long-term\n",
      "moni. fibrocalculous pancreatic diabetes:\n",
      "survival analysis. diabetes care, 19(11):1274–1278,\n",
      "1996.\n",
      "\n",
      "patricia murphy, barbara kreling, erica kathryn, mar-\n",
      "guerite stevens, joanne lynn, and jennie dulac. de-\n",
      "scription of the support intervention. journal of the\n",
      "american geriatrics society, 48(s1):s154–s161, 2000.\n",
      "\n",
      "milad nasr, reza shokri, and amir houmansadr. com-\n",
      "prehensive privacy analysis of deep learning: passive\n",
      "and active white-box inference attacks against central-\n",
      "in ieee symposium on\n",
      "ized and federated learning.\n",
      "security and privacy, 2019.\n",
      "\n",
      "herbert robbins and sutton monro. a stochastic approx-\n",
      "imation method. the annals of mathematical statistics,\n",
      "pages 400–407, 1951.\n",
      "\n",
      "m schumacher, g bastert, h bojar, k h¨ubner,\n",
      "m olschewski, w sauerbrei, c schmoor, c beyerle,\n",
      "rl neumann, and hf rauschecker. randomized 2\n",
      "x 2 trial evaluating hormonal treatment and the du-\n",
      "ration of chemotherapy in node-positive breast cancer\n",
      "patients. german breast cancer study group. journal\n",
      "of clinical oncology, 12(10):2086–2093, 1994.\n",
      "\n",
      "reza shokri and vitaly shmatikov. privacy-preserving\n",
      "deep learning.\n",
      "in proceedings of\n",
      "the 22nd acm\n",
      "sigsac conference on computer and communications\n",
      "security, pages 1310–1321, 2015.\n",
      "\n",
      "maria stepanova and lyn thomas. survival analysis\n",
      "methods for personal loan data. operations research,\n",
      "50(2):277–289, 2002.\n",
      "\n",
      "quentin styc and philippe lagacherie. predicting soil\n",
      "in 7. global\n",
      "\n",
      "depth using survival analysis models.\n",
      "workshop on digital soil mapping, 2016.\n",
      "\n",
      "toyotaro suzumura, yi zhou, natahalie baracaldo,\n",
      "guangnan ye, keith houck, ryo kawahara, ali an-\n",
      "war, lucia larise stavarache, yuji watanabe, pablo\n",
      "loyola, et al. towards federated graph learning for\n",
      "collaborative financial crimes detection. arxiv preprint\n",
      "arxiv:1909.12946, 2019.\n",
      "\n",
      "katarzyna tomczak, patrycja czerwi´nska, and maciej\n",
      "wiznerowicz. the cancer genome atlas (tcga): an im-\n",
      "measurable source of knowledge. contemporary oncol-\n",
      "ogy, 19(1a):a68, 2015.\n",
      "\n",
      "stacey truex, nathalie baracaldo, ali anwar, thomas\n",
      "steinke, heiko ludwig, rui zhang, and yi zhou. a hy-\n",
      "brid approach to privacy-preserving federated learning.\n",
      "in proceedings of the 12th acm workshop on artificial\n",
      "intelligence and security, pages 1–11, 2019.\n",
      "\n",
      "stacey truex, ling liu, ka-ho chow, mehmet emre gur-\n",
      "soy, and wenqi wei. ldp-fed: federated learning with\n",
      "local differential privacy. in proceedings of the third\n",
      "acm international workshop on edge systems, ana-\n",
      "lytics and networking, pages 61–66, 2020.\n",
      "\n",
      "wensi yang, yuhang zhang, kejiang ye, li li, and\n",
      "cheng-zhong xu. ffd: a federated learning based\n",
      "in interna-\n",
      "method for credit card fraud detection.\n",
      "tional conference on big data, pages 18–32. springer,\n",
      "2019.\n",
      "\n",
      "423\n",
      "\n",
      "\f",
      "tao yu, eugene bagdasaryan, and vitaly shmatikov. sal-\n",
      "vaging federated learning by local adaptation. arxiv\n",
      "preprint arxiv:2002.04758, 2020.\n",
      "\n",
      "bo zhao, konda reddy mopuri, and hakan bilen. idlg:\n",
      "improved deep leakage from gradients. arxiv preprint\n",
      "arxiv:2001.02610, 2020.\n",
      "\n",
      "ligeng zhu, zhijian liu, and song han. deep leakage\n",
      "in advances in neural information\n",
      "\n",
      "from gradients.\n",
      "processing systems, volume 32, 2019.\n",
      "\n",
      "appendix a. algorithms\n",
      "\n",
      "algorithm 2\n",
      "federated learning (stdfed).\n",
      "n total clients, local mini-batch size b, local epochs\n",
      "e, communication rounds tcl and learning rate η.\n",
      "initialize w0 and send the model to clients\n",
      "for r = 1, ...tcl\n",
      "\n",
      "select k clients randomly\n",
      "for each selected client k = 1, ..., k\n",
      "k ← clientupdate(k, wr−1)\n",
      "wr\n",
      "\n",
      "pk\n",
      "\n",
      "k=1\n",
      "\n",
      "k−wr−1)\n",
      "(wr\n",
      "k\n",
      "\n",
      "wr ← wr−1 +\n",
      "clientupdate(k, w)\n",
      "for client k\n",
      "for i = 1, ..., e\n",
      "\n",
      "for local batches b\n",
      "\n",
      "w ← w − η∇l(b; w)\n",
      "\n",
      "return w to server\n",
      "\n",
      "appendix b. results\n",
      "\n",
      "results for metabric and support datasets accord-\n",
      "ing to section. 4.4 and section. 4.5. the arrows indicate\n",
      "if a lower or a higher value of the metric indicates bet-\n",
      "ter utility of the model. to compare our proposed post-\n",
      "processing method with the vanilla dp federated learn-\n",
      "ing (dpfed), we have made numbers bold only when our\n",
      "method offers an advantage.\n",
      "\n",
      "algorithm 3\n",
      "differentially private federated learning\n",
      "with post processing (dpfed).\n",
      "n total clients, local mini-batch size b, local epochs\n",
      "e, communication rounds tcl,\n",
      "learning rate η,\n",
      "sensitivity s and post-processing parameter p .\n",
      "initialize w0 and send the model to clients\n",
      "for r = 1, ...tcl\n",
      "\n",
      "select k clients randomly\n",
      "for each selected client k = 1, ..., k\n",
      "k ← clientupdate(k, wr−1)\n",
      "wr\n",
      "k − wr−1\n",
      "∆wr\n",
      "(cid:16)\n",
      "∆ ˆwr\n",
      "k/max\n",
      "∆ ˆwr\n",
      "∆wr ←\n",
      "k\n",
      "k\n",
      "wr ← wr−1 + ∆wr\n",
      "\n",
      "k ← wr\n",
      "k ← ∆wr\n",
      "pk\n",
      "\n",
      "1, ||∆wr\n",
      "\n",
      "+g(0,sσi)\n",
      "\n",
      "k||2\n",
      "\n",
      "k=1\n",
      "\n",
      "s\n",
      "\n",
      "(cid:17)\n",
      "\n",
      "clientupdate(k, w)\n",
      "for client k\n",
      "for i = 1, ..., e\n",
      "\n",
      "for local batches b\n",
      "\n",
      "w ← w − η∇l(b; w)\n",
      "\n",
      "return w to server\n",
      "\n",
      "424\n",
      "\n",
      "\f",
      "table 4: metabric dataset\n",
      "\n",
      "metric\n",
      "\n",
      "c-index\n",
      "↑\n",
      "\n",
      "ibs\n",
      "↓\n",
      "\n",
      "nibll\n",
      "↓\n",
      "\n",
      "model\n",
      "deephit\n",
      "coxph\n",
      "coxcc\n",
      "coxtime\n",
      "deephit\n",
      "coxph\n",
      "coxcc\n",
      "coxtime\n",
      "deephit\n",
      "coxph\n",
      "coxcc\n",
      "coxtime\n",
      "\n",
      "non-private\n",
      "\n",
      "(ϵ = 5.4, δ = 10−3)\n",
      "\n",
      "(ϵ = 8.9, δ = 10−3)\n",
      "\n",
      "centralized\n",
      "0.68 ± 0.17\n",
      "0.64 ± 0.12\n",
      "0.62 ± 0.01\n",
      "0.63 ± 0.12\n",
      "0.16 ± 0.01\n",
      "0.17 ± 0.01\n",
      "0.17 ± 0.01\n",
      "0.17 ± 0.01\n",
      "0.50 ± 0.02\n",
      "0.50 ± 0.02\n",
      "0.51 ± 0.02\n",
      "0.51 ± 0.01\n",
      "\n",
      "stdfed\n",
      "0.65 ± 0.02\n",
      "0.65 ± 0.01\n",
      "0.62 ± 0.02\n",
      "0.64 ± 0.01\n",
      "0.17 ± 0.01\n",
      "0.18 ± 0.01\n",
      "0.17 ± 0.01\n",
      "0.17 ± 0.01\n",
      "0.52 ± 0.01\n",
      "0.48 ± 0.01\n",
      "0.52 ± 0.01\n",
      "0.51 ± 0.01\n",
      "\n",
      "dpfed\n",
      "0.51 ± 0.06\n",
      "0.50 ± 0.08\n",
      "0.50 ± 0.03\n",
      "0.53 ± 0.05\n",
      "0.21 ± 0.01\n",
      "0.20 ± 0.01\n",
      "0.19 ± 0.01\n",
      "0.21 ± 0.01\n",
      "0.67 ± 0.02\n",
      "0.57 ± 0.03\n",
      "0.57 ± 0.02\n",
      "0.60 ± 0.05\n",
      "\n",
      "dpfedpost\n",
      "0.52 ± 0.03\n",
      "0.52 ± 0.03\n",
      "0.51 ± 0.07\n",
      "0.51 ± 0.05\n",
      "0.18 ± 0.01\n",
      "0.19 ± 0.01\n",
      "0.20 ± 0.01\n",
      "0.20 ± 0.01\n",
      "0.54 ± 0.01\n",
      "0.58 ± 0.03\n",
      "0.57 ± 0.03\n",
      "0.58 ± 0.03\n",
      "\n",
      "dpfed\n",
      "0.53 ± 0.02\n",
      "0.60 ± 0.02\n",
      "0.53 ± 0.06\n",
      "0.56 ± 0.01\n",
      "0.21 ± 0.01\n",
      "0.19 ± 0.01\n",
      "0.19 ± 0.01\n",
      "0.20 ± 0.01\n",
      "0.62 ± 0.02\n",
      "0.55 ± 0.01\n",
      "0.56 ± 0.01\n",
      "0.61 ± 0.02\n",
      "\n",
      "dpfedpost\n",
      "0.57 ± 0.04\n",
      "0.63 ± 0.04\n",
      "0.55 ± 0.08\n",
      "0.55 ± 0.06\n",
      "0.18 ± 0.01\n",
      "0.18 ± 0.01\n",
      "0.18 ± 0.01\n",
      "0.19 ± 0.01\n",
      "0.55 ± 0.02\n",
      "0.55 ± 0.03\n",
      "0.55 ± 0.03\n",
      "0.53 ± 0.02\n",
      "\n",
      "table 5: support dataset\n",
      "\n",
      "metric\n",
      "\n",
      "c-index\n",
      "↑\n",
      "\n",
      "ibs\n",
      "↓\n",
      "\n",
      "nibll\n",
      "↓\n",
      "\n",
      "model\n",
      "deephit\n",
      "coxph\n",
      "coxcc\n",
      "coxtime\n",
      "deephit\n",
      "coxph\n",
      "coxcc\n",
      "coxtime\n",
      "deephit\n",
      "coxph\n",
      "coxcc\n",
      "coxtime\n",
      "\n",
      "non-private\n",
      "\n",
      "(ϵ = 5.4, δ = 10−3)\n",
      "\n",
      "(ϵ = 8.9, δ = 10−3)\n",
      "\n",
      "centralized\n",
      "0.61 ± 0.01\n",
      "0.61 ± 0.01\n",
      "0.58 ± 0.01\n",
      "0.60 ± 0.13\n",
      "0.19 ± 0.01\n",
      "0.19 ± 0.01\n",
      "0.20 ± 0.01\n",
      "0.20 ± 0.01\n",
      "0.57 ± 0.01\n",
      "0.56 ± 0.01\n",
      "0.58 ± 0.01\n",
      "0.58 ± 0.02\n",
      "\n",
      "stdfed\n",
      "0.59 ± 0.02\n",
      "0.61 ± 0.01\n",
      "0.61 ± 0.02\n",
      "0.59 ± 0.01\n",
      "0.23 ± 0.02\n",
      "0.19 ± 0.01\n",
      "0.19 ± 0.01\n",
      "0.20 ± 0.01\n",
      "0.67 ± 0.06\n",
      "0.56 ± 0.01\n",
      "0.57 ± 0.01\n",
      "0.58 ± 0.01\n",
      "\n",
      "dpfed\n",
      "0.47 ± 0.02\n",
      "0.50 ± 0.02\n",
      "0.51 ± 0.04\n",
      "0.54 ± 0.01\n",
      "0.31 ± 0.03\n",
      "0.22 ± 0.01\n",
      "0.22 ± 0.02\n",
      "0.25 ± 0.03\n",
      "0.97 ± 0.90\n",
      "0.64 ± 0.03\n",
      "0.63 ± 0.04\n",
      "0.71 ± 0.08\n",
      "\n",
      "dpfedpost\n",
      "0.49 ± 0.01\n",
      "0.51 ± 0.02\n",
      "0.50 ± 0.02\n",
      "0.51 ± 0.01\n",
      "0.25 ± 0.02\n",
      "0.21 ± 0.01\n",
      "0.22 ± 0.01\n",
      "0.21 ± 0.01\n",
      "0.70 ± 0.04\n",
      "0.61 ± 0.01\n",
      "0.63 ± 0.01\n",
      "0.60 ± 0.01\n",
      "\n",
      "dpfed\n",
      "0.49 ± 0.01\n",
      "0.51 ± 0.03\n",
      "0.53 ± 0.03\n",
      "0.49 ± 0.01\n",
      "0.26 ± 0.02\n",
      "0.21 ± 0.01\n",
      "0.21 ± 0.01\n",
      "0.23 ± 0.01\n",
      "0.75 ± 0.06\n",
      "0.62 ± 0.03\n",
      "0.60 ± 0.01\n",
      "0.66 ± 0.03\n",
      "\n",
      "dpfedpost\n",
      "0.51 ± 0.01\n",
      "0.53 ± 0.02\n",
      "0.53 ± 0.01\n",
      "0.53 ± 0.02\n",
      "0.25 ± 0.01\n",
      "0.21 ± 0.01\n",
      "0.21 ± 0.01\n",
      "0.21 ± 0.01\n",
      "0.73 ± 0.03\n",
      "0.60 ± 0.01\n",
      "0.59 ± 0.01\n",
      "0.61 ± 0.02\n",
      "\n",
      "425\n",
      "\n",
      "\u001b[5m\u001b[31m\u001b[0mngs of machine learning research 174:411–425, 2022\n",
      "\n",
      "conference on health, inference, and le\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering.txt :\u001b[0m \n",
      " schoenick, and\n",
      "oyvind tafjord. think you have solved question\n",
      "answering? try arc, the ai2 reasoning \u001b[5m\u001b[31mchallenge\u001b[0m.\n",
      "the allen institute for artificial intelligence, 2018.\n",
      "\n",
      "transformers\n",
      "\n",
      "jacob devlin, ming-\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Improving the Fairness of Chest X-ray Classifiers.txt :\u001b[0m \n",
      " ayena, alessandro blasimme, and i glenn co-\n",
      "hen. machine learning in medicine: addressing eth-\n",
      "ical \u001b[5m\u001b[31mchallenge\u001b[0ms. plos medicine, 15(11):e1002689,\n",
      "2018.\n",
      "\n",
      "sahil verma and julia rubin. fairness definitions\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___How to validate Machine Learning Models Prior to Deployment: Silent trial protocol for evaluation of real-time models at ICU.txt :\u001b[0m \n",
      " g uncertainty in clinical machine learning\n",
      "in chi ’21 workshop: realizing ai\n",
      "models.\n",
      "in healthcare:\n",
      "\u001b[5m\u001b[31mchallenge\u001b[0ms appearing in the\n",
      "wild, 2021.\n",
      "url http://francisconunes.\n",
      "me/realizingaiinhealthcarews/pape\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___ADCB: An Alzheimer’s disease simulator for benchmarking observational estimators of causal effects.txt :\u001b[0m \n",
      "  frederik barkhof, nick c fox,\n",
      "stefan klein, daniel c alexander, et al. tad-\n",
      "longitudinal evo-\n",
      "pole \u001b[5m\u001b[31mchallenge\u001b[0m: prediction of\n",
      "lution in alzheimer’s disease.\n",
      "arxiv preprint\n",
      "arxiv:1805.03909, 2018.\n",
      "\n",
      "brad\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Lead-agnostic Self-supervised Learning for Local and Global Representations of Electrocardiogram.txt :\u001b[0m \n",
      " . will two do? vary-\n",
      "ing dimensions in electrocardiography: the phy-\n",
      "sionet/computing in cardiology \u001b[5m\u001b[31mchallenge\u001b[0m 2021.\n",
      "computing in cardiology 2021, 48:1–4, 2021.\n",
      "\n",
      "ashish vaswani, noam shazeer, niki parm\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Neural Survival Clustering: Non-parametric mixture of neural networks for survival clustering.txt :\u001b[0m \n",
      " an der schaar, editors, proceedings\n",
      "of aaai spring symposium on survival predic-\n",
      "tion - algorithms, \u001b[5m\u001b[31mchallenge\u001b[0ms, and applications\n",
      "2021, volume 146 of proceedings of machine learn-\n",
      "ing research, pages 1\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Evaluating Domain Generalization for Survival Analysis in Clinical Studies.txt :\u001b[0m \n",
      " individual metas-\n",
      "tases to classification of lymph node status at the\n",
      "patient level: the camelyon17 \u001b[5m\u001b[31mchallenge\u001b[0m.\n",
      "ieee\n",
      "transactions on medical imaging, 38(2):550–560,\n",
      "2019. doi: 10.1109/tmi.2018.2867350.\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Enriching Unsupervised User Embedding via Medical Concepts.txt :\u001b[0m \n",
      " frame-\n",
      "work for topic modelling with large corpora. in\n",
      "proceedings of the lrec 2010 workshop on new\n",
      "\u001b[5m\u001b[31mchallenge\u001b[0ms for nlp frameworks, pages 45–50, val-\n",
      "letta, malta, may 2010. elra. isbn 2-9517408-\n",
      "6-7. \n"
     ]
    }
   ],
   "source": [
    "mention_matches = {name:[] for name in mentions}\n",
    "\n",
    "i=0\n",
    "for name in mentions:\n",
    "    for text_file in texts:\n",
    "        with open(text_file, 'r') as f:\n",
    "            contents = f.read()\n",
    "            #Only check for 1-for-1 correspondence\n",
    "            #AND DON'T FORGET TO LOWER CASE WHEN COMPARING!\n",
    "            contents = contents.lower()\n",
    "            low_name=name.lower()\n",
    "            if contents.find('bibliography') != -1:\n",
    "                if contents.find( low_name, contents.find('bibliography') ) != -1:\n",
    "                    get_first_occurence_context_after(contents, low_name, after='bibliography',preview_offset=100)\n",
    "                    #break\n",
    "                # get_first_occurence_context(contents, 'bibliography')\n",
    "            elif contents.find('references') != -1:\n",
    "                if contents.find( low_name, contents.find('references') ) != -1:\n",
    "                    get_first_occurence_context_after(contents, low_name, after='references',preview_offset=100)\n",
    "\n",
    "                \n",
    "            #     mention_matches[name].append(1)\n",
    "            #     get_first_occurence_context(contents, low_name)\n",
    "            # else:\n",
    "            #     mention_matches[name].append(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a37d829-faa2-485b-b6fb-2e40bc68572f",
   "metadata": {},
   "source": [
    "### 3.3 First Occurence before Bibliography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59038d54-df44-444c-94b1-80338c6c7bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_occurence_context_before(contents, low_name, before='', preview_offset = 100):\n",
    "    idx0=contents.rfind(before)\n",
    "    contents=contents[:idx0]\n",
    "    idx=contents.find(low_name)\n",
    "    if idx==-1: return 0 \n",
    "    idx_end = idx + len(low_name)\n",
    "    L = len(contents)\n",
    "    start_edge = max(0,idx-preview_offset)\n",
    "    end_edge = min(L-1,idx+preview_offset)\n",
    "    print(\"\\33[32mFound\", name, \"in\", text_file,\":\\33[0m\",'\\n',\n",
    "          contents[start_edge:idx]+'\\033[5m\\u001b[31m'+contents[idx:idx_end]+'\\33[0m'+contents[idx_end:end_edge]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91ff4923-3ddf-481a-b6e1-70ff5b7758f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFound competition in data/texts/CHIL 2021___MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering.txt :\u001b[0m \n",
      " e answer’s explanation. (✓ : the correct answer)\n",
      "\n",
      "et al., 2020) and the organization of workshops &\n",
      "\u001b[5m\u001b[31mcompetition\u001b[0ms such as the question answering in the\n",
      "medical domain & bioasq challenge (abacha et al.,\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Conference on Health, Inference, and Learning (CHIL) 2022.txt :\u001b[0m \n",
      " lated areas. the goal of the con-\n",
      "ference is to foster excellent research that addresses\n",
      "the unique \u001b[5m\u001b[31mchallenge\u001b[0ms and opportunities that arise at\n",
      "the intersection of machine learning and health.\n",
      "\n",
      "2. conf\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Practical Challenges in Differentially-Private Federated Survival Analysis of Medical Data.txt :\u001b[0m \n",
      " ng research 174:411–425, 2022\n",
      "\n",
      "conference on health, inference, and learning (chil) 2022\n",
      "\n",
      "practical \u001b[5m\u001b[31mchallenge\u001b[0ms in differentially-private federated survival analysis\n",
      "of medical data\n",
      "\n",
      "shadi rahimian\n",
      "cis\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering.txt :\u001b[0m \n",
      " anization of workshops &\n",
      "competitions such as the question answering in the\n",
      "medical domain & bioasq \u001b[5m\u001b[31mchallenge\u001b[0m (abacha et al.,\n",
      "2019; nentidis et al., 2020)\n",
      "\n",
      "however, despite these successful efforts, a\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Context-Sensitive Spelling Correction of Clinical Text via Conditional Independence.txt :\u001b[0m \n",
      " agnosis codes given the\n",
      "clinical note).\n",
      "\n",
      "such spelling correction in a clinical context has\n",
      "several \u001b[5m\u001b[31mchallenge\u001b[0ms. first, the candidate generation\n",
      "step, a critical component of most spelling correc-\n",
      "tion\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___How to validate Machine Learning Models Prior to Deployment: Silent trial protocol for evaluation of real-time models at ICU.txt :\u001b[0m \n",
      " oration pathway (blackwell et al.,\n",
      "2020; erez et al., 2021; rusin et al., 2016) poses a\n",
      "significant \u001b[5m\u001b[31mchallenge\u001b[0m in the evaluation of risk mod-\n",
      "\n",
      "els. during the retrospective validation phase of the\n",
      "mode\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Uncertainty-Aware Text-to-Program for Question Answering on Structured Electronic Health Records.txt :\u001b[0m \n",
      " s\n",
      "works proposed reinforcement learning (rl) based\n",
      "approaches.\n",
      "\n",
      "rl-based approaches, however,\n",
      "\n",
      "face \u001b[5m\u001b[31mchallenge\u001b[0ms\n",
      "caused by the large search space and sparse rewards.\n",
      "in particular, these challenges are \n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___ADCB: An Alzheimer’s disease simulator for benchmarking observational estimators of causal effects.txt :\u001b[0m \n",
      " ager\n",
      "and athey, 2018) for overviews. to assess the quali-\n",
      "ties of each estimator, various benchmark \u001b[5m\u001b[31mchallenge\u001b[0ms\n",
      "have been developed (dorie et al., 2019). see sec-\n",
      "tion 6 for a more in-depth survey.\n",
      "\n",
      "fu\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Semi-Markov Offline Reinforcement Learning for Healthcare.txt :\u001b[0m \n",
      " similar) problems are offline by nature,\n",
      "allowing for only retrospective studies. to ad-\n",
      "dress both \u001b[5m\u001b[31mchallenge\u001b[0ms, we begin by discussing\n",
      "the semi-mdp (smdp) framework, which for-\n",
      "mally handles actions o\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Lead-agnostic Self-supervised Learning for Local and Global Representations of Electrocardiogram.txt :\u001b[0m \n",
      " for evaluation, we utilize the cinc score, which\n",
      "is introduced in physionet/computing in cardiology\n",
      "\u001b[5m\u001b[31mchallenge\u001b[0m 2021 (reyna et al., 2021). this metric is\n",
      "a weighted version of the traditional accuracy m\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Learning Unsupervised Representations for ICU Timeseries.txt :\u001b[0m \n",
      " atients with similar underlying\n",
      "conditions, track disease progression over time,\n",
      "and much more. the \u001b[5m\u001b[31mchallenge\u001b[0m with medical\n",
      "time series however, is the lack of well-defined\n",
      "labels for a given patient’s\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Neural Survival Clustering: Non-parametric mixture of neural networks for survival clustering.txt :\u001b[0m \n",
      " ach does not aim to maximise\n",
      "discriminative performances but to discover clus-\n",
      "ters, it nonetheless \u001b[5m\u001b[31mchallenge\u001b[0ms other state-of-the-\n",
      "art methods.\n",
      "\n",
      "• our method identifies\n",
      "\n",
      "survival distributions\n",
      "\n",
      "aligne\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Multi-Task Adversarial Learning for Treatment Effect Estimation in Basket Trials.txt :\u001b[0m \n",
      " usal inference set-\n",
      "ting includes, but is not limited to basket tri-\n",
      "als. this setting has the same \u001b[5m\u001b[31mchallenge\u001b[0ms as\n",
      "the traditional causal inference problem, i.e.,\n",
      "missing counterfactual outcomes under \n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Evaluating Domain Generalization for Survival Analysis in Clinical Studies.txt :\u001b[0m \n",
      " may not neces-\n",
      "sarily help to identify potential generalizability issues\n",
      "either. an additional open \u001b[5m\u001b[31mchallenge\u001b[0m is model selec-\n",
      "tion from a set of candidate models, which can lead\n",
      "to severe performance \n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Enriching Unsupervised User Embedding via Medical Concepts.txt :\u001b[0m \n",
      "  word2vec embeddings (mikolov\n",
      "et al., 2013). finding hidden structures to distinguish\n",
      "patients is a \u001b[5m\u001b[31mchallenge\u001b[0m for unsupervised user embed-\n",
      "dings to compress patient features from clinical notes.\n",
      "unsup\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Estimating Model Performance on External Samples from Their Limited Statistical Characteristics.txt :\u001b[0m \n",
      " y become prohibitively costly; large-\n",
      "\n",
      "scale optimization techniques may be used to over-\n",
      "come such \u001b[5m\u001b[31mchallenge\u001b[0ms.\n",
      "\n",
      "we believe that the proposed methodology can\n",
      "serve as a building block in network studi\n",
      "\u001b[32mFound challenge in data/texts/CHIL 2021___Counterfactually Guided Policy Transfer in Clinical Settings.txt :\u001b[0m \n",
      " n shift, encountered when using a trained\n",
      "model for a new patient population, creates sig-\n",
      "nificant \u001b[5m\u001b[31mchallenge\u001b[0ms for sequential decision making\n",
      "in healthcare since the target domain may be\n",
      "both data-sca\n"
     ]
    }
   ],
   "source": [
    "mention_matches = {name:[] for name in mentions}\n",
    "\n",
    "i=0\n",
    "for name in mentions:\n",
    "    for text_file in texts:\n",
    "        with open(text_file, 'r') as f:\n",
    "            contents = f.read()\n",
    "            #Only check for 1-for-1 correspondence\n",
    "            #AND DON'T FORGET TO LOWER CASE WHEN COMPARING!\n",
    "            contents = contents.lower()\n",
    "            low_name=name.lower()\n",
    "            if contents.find('bibliography') != -1:\n",
    "                if contents.find( low_name ) != -1:\n",
    "                    get_first_occurence_context_before(contents, low_name, before='bibliography',preview_offset=100)\n",
    "                    #break\n",
    "                # get_first_occurence_context(contents, 'bibliography')\n",
    "            elif contents.find('references') != -1:\n",
    "                if contents.find( low_name ) != -1:\n",
    "                    get_first_occurence_context_before(contents, low_name, before='references',preview_offset=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3e720eb-976b-47a8-acfc-014f27e87a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mention_matches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa8ace4-411e-4992-b48d-55a57c322689",
   "metadata": {},
   "source": [
    "### 3.4 Get occurences in datasets used in \"Data and Code Availability\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e9e9f834-7fae-4e76-92b7-e36b2bd7aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occurences_in_dasa(contents, low_name, before='', preview_offset = 100):\n",
    "    idx0=contents.find(\"data and code availability\")\n",
    "    contents=contents[idx0:]\n",
    "    idx=contents.find(low_name)\n",
    "    if idx==-1: return 0 \n",
    "    idx_end = idx + len(low_name)\n",
    "    L = len(contents)\n",
    "    start_edge = max(0,idx-preview_offset)\n",
    "    end_edge = min(L-1,idx+preview_offset)\n",
    "    print(\"\\33[32mFound\", name, \"in\", text_file,\":\\33[0m\",'\\n',\n",
    "          contents[start_edge:idx]+'\\033[5m\\u001b[31m'+contents[idx:idx_end]+'\\33[0m'+contents[idx_end:end_edge]\n",
    "         )\n",
    "    \n",
    "def get_dasa(contents):\n",
    "    \"\"\"Get the Data and Code Availability section from CHIL papers\"\"\"\n",
    "    idx0=contents.find(\"data and code availability\")\n",
    "    contents=contents[idx0:]\n",
    "    idxend=contents.find('1. introduction')\n",
    "    contents=contents[:idxend]\n",
    "    return contents\n",
    "    #print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "264868cd-d109-4ccc-abfe-240efea801bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mention_matches = {name:[] for name in mentions}\n",
    "items = {text_file:[] for text_file in texts}\n",
    "\n",
    "#limit = 10\n",
    "#i=0\n",
    "for text_file in texts:\n",
    "    #if i>limit: break\n",
    "    with open(text_file, 'r') as f:\n",
    "        contents = f.read()\n",
    "        #Only check for 1-for-1 correspondence\n",
    "        #AND DON'T FORGET TO LOWER CASE WHEN COMPARING!\n",
    "        contents = contents.lower()\n",
    "        #print(contents)\n",
    "\n",
    "        items[text_file] = get_dasa(contents)\n",
    "        #print('{}: ******************'.format(text_file))\n",
    "        #low_name=name.lower()\n",
    "        #if contents.find(low_name) != -1:\n",
    "            #mention_matches[name].append(1)\n",
    "        #    print(get_dasa(contents))\n",
    "        #else:\n",
    "            #mention_matches[name].append(0)\n",
    "        #    pass\n",
    "    #i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f8e20e-65e3-47d1-8c6b-be74665bae66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51922fd-e825-4e36-9b10-a054d26d233e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e549fbc8-2dea-41fd-a0d2-2653ab116a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_section(contents, section_header=\"data and code availability\", section_end=['1. introduction','© 2022']):\n",
    "    \"\"\"Get the Data and Code Availability section from CHIL papers\"\"\"\n",
    "    \n",
    "    contents = contents.lower()\n",
    "    contents = contents.replace(\"\\n\\n\", \"$$$\" )\n",
    "    contents = contents.replace(\"-\\n\", \"\" )\n",
    "    # contents = contents.replace(\"\\n\", \"\" )\n",
    "    contents = contents.replace(\"$$$\", \"\\n\" )\n",
    "\n",
    "    idx0=contents.find(section_header)\n",
    "    contents=contents[idx0:]\n",
    "    for end in section_end:\n",
    "        idxend=contents.find(end)\n",
    "        if idxend==-1: continue\n",
    "        contents=contents[:idxend]\n",
    "        return contents\n",
    "    #print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "24e3fd73-235b-45af-b25e-5ed51e9a75ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "items = {text_file:[] for text_file in texts}\n",
    "\n",
    "for text_file in texts:\n",
    "    with open(text_file, 'r') as f:\n",
    "        contents = f.read()\n",
    "        items[text_file] = get_section(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8b45f-8613-4bc4-a0b2-977f5796fefd",
   "metadata": {},
   "source": [
    "## 4. WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "85374435-ce78-465a-b3c6-bbbdf0a470dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for name in mention_matches:\n",
    "#     merged_dict[name]=mention_matches[name]\n",
    "# for keyword in keyword_matches:\n",
    "#     merged_dict[keyword]=keyword_matches[keyword]\n",
    "\n",
    "# NEW CSV USING get_dasa function from 3.4\n",
    "\n",
    "# for item in items:\n",
    "#     print(item)\n",
    "#     print(items[item])\n",
    "\n",
    "pd.DataFrame( [ items[item] for item in items] ).iloc[1][0]\n",
    "\n",
    "# texts[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "3e6bf04d-dfe3-4cdd-9779-4b8007e0ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TODO:\n",
    "# print(\"* SWITCH TO MULTI-MATCHING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127cbc28-e1ce-43d4-a5e1-f507fb5a5427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
