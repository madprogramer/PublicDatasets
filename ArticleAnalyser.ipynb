{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3ff45d6-f5c4-44fb-aef7-a9edc0596a90",
   "metadata": {},
   "source": [
    "# PublicDatasets (Analyser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4b8014-f228-46f3-a745-bfb4e63cbc60",
   "metadata": {},
   "source": [
    "## 1. Re-reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17433dfb-a29b-4374-9112-0ad4afa2224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_separator = '___'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba056aa2-a5a2-4c12-923c-814b78cfa6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a553a422-2566-4a43-824b-6baaff9027d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_paper_table = pd.read_csv('data/ResearchPapers.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd1b100a-f80d-4f13-ac61-88717d87a31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Venue</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ML4H 2020</td>\n",
       "      <td>Interpretable Epilepsy Detection in Routine, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML4H 2020</td>\n",
       "      <td>EEG-GCNN: Augmenting Electroencephalogram-base...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML4H 2020</td>\n",
       "      <td>Confounding Feature Acquisition for Causal Eff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ML4H 2020</td>\n",
       "      <td>Addressing the Real-world Class Imbalance Prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ML4H 2020</td>\n",
       "      <td>A Neural SIR Model for Global Forecasting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Venue                                              Title\n",
       "0  ML4H 2020  Interpretable Epilepsy Detection in Routine, I...\n",
       "1  ML4H 2020  EEG-GCNN: Augmenting Electroencephalogram-base...\n",
       "2  ML4H 2020  Confounding Feature Acquisition for Causal Eff...\n",
       "3  ML4H 2020  Addressing the Real-world Class Imbalance Prob...\n",
       "4  ML4H 2020          A Neural SIR Model for Global Forecasting"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_paper_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d352189-d02b-4723-b92a-e14809c0863b",
   "metadata": {},
   "source": [
    "### 1.a get file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7384f08-4eb9-4fac-97d1-83323d9f309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_filename(v,t,path='data/texts/'):\n",
    "    return path+v+special_separator+t+'.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a0986de-9dc4-4b68-9f93-183afa7591d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for index, row in research_paper_table.iterrows():\n",
    "    texts.append(get_text_filename(row[\"Venue\"],row[\"Title\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1826af-7e31-4cce-8ea9-870b240621d7",
   "metadata": {},
   "source": [
    "## 2. Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d1ccae-ba20-4fa1-b3dc-c63b61345f12",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1 Explicit Mentions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c03b046d-8b2e-4309-9151-cb70347e2b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions = [\n",
    "    #'kaggle',\n",
    "    #'competition',\n",
    "    #'grand',\n",
    "    # 'challenge',\n",
    "    #'dataset',\n",
    "    #'data set',\n",
    "    'datasets',\n",
    "    'data sets',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e88341a-1df1-446d-8972-68ddc540c40e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2 Related Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82c8d246-8920-4d8a-8820-51d34e0c626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\n",
    "    # \"lung cancer\",\n",
    "    # \"nodule\",\n",
    "    # \"competition\",\n",
    "    # \"kaggle dataset\",\n",
    "    # \"kaggle\",\n",
    "    # \"deep learning\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec4a0c0-67fe-4a63-907b-6589dd2fc228",
   "metadata": {},
   "source": [
    "## 3. Relation Queriers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc6afde-cc15-470e-a6b5-aa69358c095c",
   "metadata": {},
   "source": [
    "### 3.1 First Occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78541906-e640-4d1e-b4e4-2506a3d69f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_occurence_context(contents, low_name, preview_offset = 100):\n",
    "    idx=contents.find(low_name)\n",
    "    idx_end = idx + len(low_name)\n",
    "    L = len(contents)\n",
    "    start_edge = max(0,idx-preview_offset)\n",
    "    end_edge = min(L-1,idx+preview_offset)\n",
    "    print(\"\\33[32mFound\", name, \"in\", text_file,\":\\33[0m\",'\\n',\n",
    "          contents[start_edge:idx]+'\\033[5m\\u001b[31m'+contents[idx:idx_end]+'\\33[0m'+contents[idx_end:end_edge]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4348c61-612d-4a0a-bbc8-52501f1013c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFound datasets in data/texts/ML4H 2020___EEG-GCNN: Augmenting Electroencephalogram-based Neurological Disease Diagnosis using a Domain-guided Graph Convolutional Neural Network.txt :\u001b[0m \n",
      " ress this limitation as\n",
      "best we could, we undertook the same pre-\n",
      "processing steps for both the eeg \u001b[5m\u001b[31mdatasets\u001b[0m.\n",
      "regardless, future studies including eegs\n",
      "of both controls and patients recorded using\n",
      "the\n",
      "\u001b[32mFound datasets in data/texts/ML4H 2020___Confounding Feature Acquisition for Causal Effect Estimation.txt :\u001b[0m \n",
      " deployed to acquire them. this is a\n",
      "relevant setting in healthcare as some observa-\n",
      "tional clinical \u001b[5m\u001b[31mdatasets\u001b[0m used for causal studies\n",
      "recruit a cohort, and then acquire additional\n",
      "data for samples in t\n",
      "\u001b[32mFound datasets in data/texts/ML4H 2020___Addressing the Real-world Class Imbalance Problem in Dermatology.txt :\u001b[0m \n",
      " nd pro-\n",
      "posed modeling framework (b).\n",
      "\n",
      "as many skin conditions occur\n",
      "\n",
      "infre-\n",
      "quently in real-world, \u001b[5m\u001b[31mdatasets\u001b[0m collected from\n",
      "a natural patient population are highly im-\n",
      "balanced, with few examples for \n",
      "\u001b[32mFound datasets in data/texts/ML4H 2020___CheXphoto: 10,000+ Photos and Transformations of Chest X-rays for Benchmarking Deep Learning Robustness.txt :\u001b[0m \n",
      " deep\n",
      "learning algorithms for automated chest x-\n",
      "ray interpretation have been made possible\n",
      "by large \u001b[5m\u001b[31mdatasets\u001b[0m [3, 4].\n",
      "in controlled set-\n",
      "tings, these deep learning algorithms can\n",
      "learn from labeled dat\n",
      "\u001b[32mFound datasets in data/texts/ML4H 2020___3D Photography Based Neural Network Craniosynostosis Triaging System.txt :\u001b[0m \n",
      " xis to help naturally augment the\n",
      "dataset. it is of importance to note that the\n",
      "validation and test \u001b[5m\u001b[31mdatasets\u001b[0m did not undergo\n",
      "any augmentations, and no ﬂipped images\n",
      "exist within either datasets.\n",
      "\n",
      "2.4.\n",
      "\u001b[32mFound datasets in data/texts/ML4H 2020___Attend and Decode: 4D fMRI Task State Decoding Using Attention Models.txt :\u001b[0m \n",
      " )\n",
      "van essen et al. (2013); glasser et al. (2016b)\n",
      "neuroimaging dataset, one of the most preva-\n",
      "lent \u001b[5m\u001b[31mdatasets\u001b[0m for brain imaging studies. hcp\n",
      "contains multiple types of neuroimaging, de-\n",
      "mographic infor\n",
      "\u001b[32mFound datasets in data/texts/ML4H 2020___TL-Lite: Temporal Visualization and Learning for Clinical Forecasting.txt :\u001b[0m \n",
      " e’s ease of use.\n",
      "limitations and future work. there\n",
      "are limitations to tl-lite. users who pos-\n",
      "sess \u001b[5m\u001b[31mdatasets\u001b[0m with column name mismatches\n",
      "will need to undertake an extensive annota-\n",
      "tion eﬀort beyond t\n",
      "\u001b[32mFound datasets in data/texts/MIDL 2021___Hybrid optimization between iterative and network fine-tuning reconstructions for fast quantitative susceptibility mapping.txt :\u001b[0m \n",
      " l., 2020). probabilistic\n",
      "dipole inversion (pdi) adapted the pre-trained network to diﬀerent patient \u001b[5m\u001b[31mdatasets\u001b[0m using\n",
      "variational inference (zhang et al., 2020d,c). fidelity imposed network edit (fine) d\n",
      "\u001b[32mFound datasets in data/texts/ML4H 2020___DeepHeartBeat: Latent trajectory learning of cardiac cycles using cardiac ultrasounds.txt :\u001b[0m \n",
      " res and\n",
      "training procedure for the diﬀerent experi-\n",
      "ments the reader is referred to appendix a.\n",
      "\n",
      "4. \u001b[5m\u001b[31mdatasets\u001b[0m\n",
      "\n",
      "(2)\n",
      "\n",
      "4.1. echocardiogram video data\n",
      "\n",
      "which consists of a reconstruction error term\n",
      "and a r\n",
      "\u001b[32mFound data sets in data/texts/ML4H 2020___Attend and Decode: 4D fMRI Task State Decoding Using Attention Models.txt :\u001b[0m \n",
      " regions and\n",
      "frame important for task decoding. future\n",
      "work includes transferring band to other\n",
      "fmri \u001b[5m\u001b[31mdata sets\u001b[0m, such as adhd, or to other\n",
      "modalities of medical imaging.\n",
      "\n",
      "4. https://nilearn.github.io/\n",
      "\n",
      "\n",
      "\u001b[32mFound data sets in data/texts/ML4H 2020___TL-Lite: Temporal Visualization and Learning for Clinical Forecasting.txt :\u001b[0m \n",
      "  machine learning elements. we\n",
      "demonstrate the tool with three use cases\n",
      "based on two large private \u001b[5m\u001b[31mdata sets\u001b[0m and\n",
      "a public subset.\n",
      "a demo of the tool\n",
      "is available at: https://www.andrew.cmu.\n",
      "edu/user/\n",
      "\u001b[32mFound data sets in data/texts/ML4H 2020___DeepHeartBeat: Latent trajectory learning of cardiac cycles using cardiac ultrasounds.txt :\u001b[0m \n",
      " yclic trajectory in a lower dimensional\n",
      "space. we evaluated our model on large pub-\n",
      "licly available \u001b[5m\u001b[31mdata sets\u001b[0m in a variety of ex-\n",
      "periments and, thereby, touching upon sev-\n",
      "eral aspects of practical i\n"
     ]
    }
   ],
   "source": [
    "mention_matches = {name:[] for name in mentions}\n",
    "\n",
    "limit = 10\n",
    "for name in mentions:\n",
    "    i=0\n",
    "    for text_file in texts:\n",
    "        if i>limit: break\n",
    "        with open(text_file, 'r') as f:\n",
    "            contents = f.read()\n",
    "            #Only check for 1-for-1 correspondence\n",
    "            #AND DON'T FORGET TO LOWER CASE WHEN COMPARING!\n",
    "            contents = contents.lower()\n",
    "            low_name=name.lower()\n",
    "            if contents.find(low_name) != -1:\n",
    "                mention_matches[name].append(1)\n",
    "                get_first_occurence_context(contents, low_name)\n",
    "            else:\n",
    "                mention_matches[name].append(0)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96962576-45d8-434b-94aa-f0e583726445",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_matches = {keyword:[] for keyword in keywords}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edc8cc2d-bfc8-4edd-bc24-fed3563102f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIPPING\n",
    "# for keyword in keywords:\n",
    "#     for text_file in texts:\n",
    "#         with open(text_file, 'r') as f:\n",
    "#             contents = f.read()\n",
    "#             #Only check for 1-for-1 correspondence\n",
    "#             #AND DON'T FORGET TO LOWER CASE WHEN COMPARING!\n",
    "#             contents = contents.lower()\n",
    "#             low_key=keyword.lower()\n",
    "#             if contents.find(low_key) != -1:\n",
    "#                 keyword_matches[keyword].append(1)\n",
    "#                 idx=contents.find(low_key)\n",
    "#                 print(\"Found\", keyword, \"in\", text_file,\":\",contents[idx-preview_offset:idx+preview_offset])\n",
    "#             else:\n",
    "#                 keyword_matches[keyword].append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf70179-e276-4aab-9507-b7b46ffe826d",
   "metadata": {},
   "source": [
    "### 3.2 First Occurence in Bibliography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bba220c-ae3f-424f-a482-807d9b9d2cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_occurence_context_after(contents, low_name, after='', preview_offset = 100):\n",
    "    idx0=contents.rfind(after)\n",
    "    idx=contents.find(low_name,idx0)\n",
    "    idx_end = idx + len(low_name)\n",
    "    L = len(contents)\n",
    "    start_edge = max(0,idx-preview_offset)\n",
    "    end_edge = min(L-1,idx+preview_offset)\n",
    "    print(\"\\33[32mFound\", name, \"in\", text_file,\":\\33[0m\",'\\n',\n",
    "          contents[start_edge:idx]+'\\033[5m\\u001b[31m'+contents[idx:idx_end]+'\\33[0m'+contents[idx_end:end_edge]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2397011b-6a3d-4654-a981-5d2d2ea5461a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFound competition in data/texts/MIDL 2021___MoCo Pretraining Improves Representation and Transferability of Chest X-ray Models.txt :\u001b[0m \n",
      " main paper, we also conducted\n",
      "follow-up experiments evaluating moco-cxr performance on the chexpert \u001b[5m\u001b[31mcompetition\u001b[0m task patholo-\n",
      "gies. these experiments were done exclusively with the resnet18 backbone.\n",
      "\n",
      "\u001b[32mFound competition in data/texts/MIDL 2021___Understanding and Visualizing Generalization in UNets.txt :\u001b[0m \n",
      " rolina\n",
      "dziugaite, samy bengio, suriya gunasekar, isabelle guyon, and behnam neyshabur.\n",
      "neurips 2020 \u001b[5m\u001b[31mcompetition\u001b[0m: predicting generalization in deep learning, 2020.\n",
      "\n",
      "nitish shirish keskar, dheevatsa mud\n",
      "\u001b[32mFound competition in data/texts/MIDL 2021___Weakly-supervised High-resolution Segmentation of Mammography Images for Breast Cancer Diagnosis.txt :\u001b[0m \n",
      "  related to artiﬁcial intelligence research in medical imaging and the importance\n",
      "of image analysis \u001b[5m\u001b[31mcompetition\u001b[0ms. radiology: artiﬁcial intelligence, 1(1):e180031, 2019.\n",
      "\n",
      "shaoqing ren, kaiming he, ross\n",
      "\u001b[32mFound competition in data/texts/CHIL 2021___Practical Challenges in Differentially-Private Federated Survival Analysis of Medical Data.txt :\u001b[0m \n",
      " hadiji, marc m¨uller, youngjun joo,\n",
      "jiyeon lee, inchon hwang, and kyung-joong kim.\n",
      "game data mining \u001b[5m\u001b[31mcompetition\u001b[0m on churn prediction\n",
      "and survival analysis using commercial game log data.\n",
      "ieee transacti\n",
      "\u001b[32mFound competition in data/texts/CHIL 2021___ADCB: An Alzheimer’s disease simulator for benchmarking observational estimators of causal effects.txt :\u001b[0m \n",
      "  automated versus do-it-yourself\n",
      "methods for causal inference: lessons learned from\n",
      "a data analysis \u001b[5m\u001b[31mcompetition\u001b[0m. statistical science, 34\n",
      "(1):43–68, 2019.\n",
      "\n",
      "martin r farlow, michael l miller, and vojisl\n",
      "\u001b[32mFound competition in data/texts/ML4H 2021___End-to-End Sequential Sampling and Reconstruction for MRI.txt :\u001b[0m \n",
      " n, c lawrence zitnick, et al. advancing ma-\n",
      "chine learning for mr image reconstruction with an\n",
      "open \u001b[5m\u001b[31mcompetition\u001b[0m: overview of the 2019 fastmri\n",
      "challenge. magnetic resonance in medicine, 84(6):\n",
      "3054–307\n",
      "\u001b[32mFound grand in data/texts/MIDL 2021___Weakly Supervised Volumetric Segmentation via Self-taught Shape Denoising Model.txt :\u001b[0m \n",
      " ut and boxprior, especially with a large margin\n",
      "on 10% labeled-slice setting.\n",
      "\n",
      "3. https://promise12.\u001b[5m\u001b[31mgrand\u001b[0m-challenge.org\n",
      "\n",
      "282\n",
      "\n",
      "\f",
      "weakly supervised segmentation via self-taught model\n",
      "\n",
      "table 6: quantitati\n",
      "\u001b[32mFound grand in data/texts/MIDL 2021___Discrete Pseudohealthy Synthesis: Aortic Root Shape Typification and Type Classification with Pathological Prior.txt :\u001b[0m \n",
      " t tee images. medical image analysis, 20(1):162–172, 2015.\n",
      "\n",
      "haibo ni, stefano morotti, and eleonora \u001b[5m\u001b[31mgrand\u001b[0mi. a heart for diversity: simulating vari-\n",
      "ability in cardiac arrhythmia research. frontiers in\n",
      "\u001b[32mFound grand in data/texts/CHIL 2021___Learning Unsupervised Representations for ICU Timeseries.txt :\u001b[0m \n",
      " -\n",
      "national conference on knowledge discovery and\n",
      "data mining, pages 85–94, 2014.\n",
      "\n",
      "ben wellner, joan \u001b[5m\u001b[31mgrand\u001b[0m, elizabeth canzone, matt\n",
      "coarr, patrick w brady, jeffrey simmons, eric\n",
      "kirkendall, nathan dean\n",
      "\u001b[32mFound grand in data/texts/CHIL 2021___How to validate Machine Learning Models Prior to Deployment: Silent trial protocol for evaluation of real-time models at ICU.txt :\u001b[0m \n",
      " .\n",
      "implementing ma-\n",
      "chine learning in medicine. cmaj, 193(34):e1351–\n",
      "e1357, 2021.\n",
      "\n",
      "ben wellner, joan \u001b[5m\u001b[31mgrand\u001b[0m, elizabeth canzone, matt\n",
      "coarr, patrick w brady, jeffrey simmons, eric\n",
      "kirkendall, nathan dean\n"
     ]
    }
   ],
   "source": [
    "mention_matches = {name:[] for name in mentions}\n",
    "\n",
    "i=0\n",
    "for name in mentions:\n",
    "    for text_file in texts:\n",
    "        with open(text_file, 'r') as f:\n",
    "            contents = f.read()\n",
    "            #Only check for 1-for-1 correspondence\n",
    "            #AND DON'T FORGET TO LOWER CASE WHEN COMPARING!\n",
    "            contents = contents.lower()\n",
    "            low_name=name.lower()\n",
    "            if contents.find('bibliography') != -1:\n",
    "                if contents.find( low_name, contents.find('bibliography') ) != -1:\n",
    "                    get_first_occurence_context_after(contents, low_name, after='bibliography',preview_offset=100)\n",
    "                    #break\n",
    "                # get_first_occurence_context(contents, 'bibliography')\n",
    "            elif contents.find('references') != -1:\n",
    "                if contents.find( low_name, contents.find('references') ) != -1:\n",
    "                    get_first_occurence_context_after(contents, low_name, after='references',preview_offset=100)\n",
    "\n",
    "                \n",
    "            #     mention_matches[name].append(1)\n",
    "            #     get_first_occurence_context(contents, low_name)\n",
    "            # else:\n",
    "            #     mention_matches[name].append(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a37d829-faa2-485b-b6fb-2e40bc68572f",
   "metadata": {},
   "source": [
    "### 3.3 First Occurence before Bibliography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59038d54-df44-444c-94b1-80338c6c7bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_occurence_context_before(contents, low_name, before='', preview_offset = 100):\n",
    "    idx0=contents.rfind(before)\n",
    "    contents=contents[:idx0]\n",
    "    idx=contents.find(low_name)\n",
    "    if idx==-1: return 0 \n",
    "    idx_end = idx + len(low_name)\n",
    "    L = len(contents)\n",
    "    start_edge = max(0,idx-preview_offset)\n",
    "    end_edge = min(L-1,idx+preview_offset)\n",
    "    print(\"\\33[32mFound\", name, \"in\", text_file,\":\\33[0m\",'\\n',\n",
    "          contents[start_edge:idx]+'\\033[5m\\u001b[31m'+contents[idx:idx_end]+'\\33[0m'+contents[idx_end:end_edge]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91ff4923-3ddf-481a-b6e1-70ff5b7758f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFound kaggle in data/texts/MIDL 2021___GOAL: Gist-set Online Active Learning for Efficient Chest X-ray Image Annotation.txt :\u001b[0m \n",
      " , 2019), which contains\n",
      "86,477 positive instances out of 191,027 frontal instances.\n",
      "\n",
      "1. https://www.\u001b[5m\u001b[31mkaggle\u001b[0m.com/c/rsna-pneumonia-detection challenge\n",
      "\n",
      "546\n",
      "\n",
      "\f",
      "goal: gist-set online active learning for eff\n",
      "\u001b[32mFound kaggle in data/texts/MIDL 2021___Embedding-based Instance Segmentation in Microscopy.txt :\u001b[0m \n",
      "  2012)3, the usiigaci nih/3t3 phase-contrast\n",
      "dataset (tsai et al., 2019), and the dsb data from the \u001b[5m\u001b[31mkaggle\u001b[0m data science bowl challenge\n",
      "\n",
      "3. we used the c. elegans infection live/dead image set version \n",
      "\u001b[32mFound kaggle in data/texts/ML4H 2021___How Transferable are Self-supervised Features in Medical Image Classification Tasks?.txt :\u001b[0m \n",
      " bels are provided. hence, for\n",
      "all performance evaluations on patchcam, we submit\n",
      "our predictions to \u001b[5m\u001b[31mkaggle\u001b[0m.\n",
      "\n",
      "without\n",
      "\n",
      "distillation\n",
      "\n",
      "dino knowledge\n",
      "labels\n",
      "(caron et al., 2021b) matches the output proba\n",
      "\u001b[32mFound competition in data/texts/ML4H 2020___CheXphoto: 10,000+ Photos and Transformations of Chest X-rays for Benchmarking Deep Learning Robustness.txt :\u001b[0m \n",
      "  allow us to run\n",
      "arbitrary code submissions on the withheld\n",
      "\n",
      "1. https://stanfordmlgroup.github.io/\n",
      "\n",
      "\u001b[5m\u001b[31mcompetition\u001b[0ms/chexphoto\n",
      "\n",
      "325\n",
      "\n",
      "\f",
      "chexphoto\n",
      "\n",
      "test set. once a user has successfully up-\n",
      "loaded their cod\n",
      "\u001b[32mFound competition in data/texts/ML4H 2020___Appropriate Evaluation of Diagnostic Utility of Machine Learning Algorithm Generated Images.txt :\u001b[0m \n",
      " 1. datasets\n",
      "\n",
      "used\n",
      "\n",
      "(https:\n",
      "\n",
      "chexpert\n",
      "\n",
      "to\n",
      "dataset\n",
      "and mimic-cxr\n",
      "\n",
      "we\n",
      "the\n",
      "//stanfordmlgroup.github.io/\n",
      "\u001b[5m\u001b[31mcompetition\u001b[0ms/chexpert/)\n",
      "train\n",
      "our model\n",
      "(https://doi.org/10.13026/c2jt1q)\n",
      "dataset to externally test\n",
      "\u001b[32mFound competition in data/texts/MIDL 2021___MoCo Pretraining Improves Representation and Transferability of Chest X-ray Models.txt :\u001b[0m \n",
      " ised training agent. the model is\n",
      "subsequently tuned using chest x-ray images.\n",
      "\n",
      "with other chexpert \u001b[5m\u001b[31mcompetition\u001b[0m tasks (cardiomegaly, consolidation, edema and atelectasis) from\n",
      "irvin et al. (2019) to v\n",
      "\u001b[32mFound competition in data/texts/MIDL 2021___Automated triaging of head MRI examinations using convolutional neural networks.txt :\u001b[0m \n",
      "  king’s health partners challenge fund, nvidia (through the\n",
      "unrestricted use of a gpu obtained in a \u001b[5m\u001b[31mcompetition\u001b[0m), and the wellcome/engineering and\n",
      "physical sciences research council center for medical\n",
      "\u001b[32mFound competition in data/texts/MIDL 2021___Understanding and Visualizing Generalization in UNets.txt :\u001b[0m \n",
      " gradients of the weights with respect to many perturbed inputs.\n",
      "\n",
      "to this end, the neurips 2020 pgdl \u001b[5m\u001b[31mcompetition\u001b[0m (jiang et al., 2020) was conducted\n",
      "to identify tractable approaches to predict generaliz\n",
      "\u001b[32mFound competition in data/texts/MIDL 2021___Weakly Supervised Volumetric Segmentation via Self-taught Shape Denoising Model.txt :\u001b[0m \n",
      " sting.\n",
      "\n",
      "for all datasets, we use the standard evaluation metric dice coefﬁcient (dice).\n",
      "\n",
      "1. https://\u001b[5m\u001b[31mcompetition\u001b[0ms.codalab.org/competitions/21145\n",
      "2. http://atriaseg2018.cardiacatlas.org/\n",
      "\n",
      "273\n",
      "\n",
      "\f",
      "weakly s\n",
      "\u001b[32mFound competition in data/texts/CHIL 2021___MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering.txt :\u001b[0m \n",
      " e answer’s explanation. (✓ : the correct answer)\n",
      "\n",
      "et al., 2020) and the organization of workshops &\n",
      "\u001b[5m\u001b[31mcompetition\u001b[0ms such as the question answering in the\n",
      "medical domain & bioasq challenge (abacha et al.,\n",
      "\u001b[32mFound competition in data/texts/ML4H 2021___How Transferable are Self-supervised Features in Medical Image Classification Tasks?.txt :\u001b[0m \n",
      "  pixel of\n",
      "tumor tissue, it will be positive. the data version we\n",
      "use is the curated one from kaggle \u001b[5m\u001b[31mcompetition\u001b[0m1 that\n",
      "removes all the duplicated patches and comes with a\n",
      "default train/test split. the \n",
      "\u001b[32mFound grand in data/texts/MIDL 2021___Cluster-to-Conquer: A Framework for End-to-End Multi-Instance Learning for Whole Slide Image Classification.txt :\u001b[0m \n",
      " nce of the c2c framework on\n",
      "multi-class and sub-type classiﬁcation problems.\n",
      "\n",
      "3. https://camelyon16.\u001b[5m\u001b[31mgrand\u001b[0m-challenge.org/results/\n",
      "\n",
      "689\n",
      "\n",
      "\f",
      "c2c\n",
      "\n",
      "acknowledgments\n",
      "\n",
      "this work was supported by niddk of the na\n",
      "\u001b[32mFound grand in data/texts/MIDL 2021___Weakly-supervised High-resolution Segmentation of Mammography Images for Breast Cancer Diagnosis.txt :\u001b[0m \n",
      "  for breast cancer diagnosis\n",
      "\n",
      "kangning liu1\n",
      "yiqiu shen1\n",
      "nan wu1\n",
      "jakub chł˛edowski4\n",
      "carlos fernandez-\u001b[5m\u001b[31mgrand\u001b[0ma*1,2\n",
      "krzysztof j. geras*3,1\n",
      "1 nyu center for data science\n",
      "2 courant institute of mathematical \n"
     ]
    }
   ],
   "source": [
    "mention_matches = {name:[] for name in mentions}\n",
    "\n",
    "i=0\n",
    "for name in mentions:\n",
    "    for text_file in texts:\n",
    "        with open(text_file, 'r') as f:\n",
    "            contents = f.read()\n",
    "            #Only check for 1-for-1 correspondence\n",
    "            #AND DON'T FORGET TO LOWER CASE WHEN COMPARING!\n",
    "            contents = contents.lower()\n",
    "            low_name=name.lower()\n",
    "            if contents.find('bibliography') != -1:\n",
    "                if contents.find( low_name ) != -1:\n",
    "                    get_first_occurence_context_before(contents, low_name, before='bibliography',preview_offset=100)\n",
    "                    #break\n",
    "                # get_first_occurence_context(contents, 'bibliography')\n",
    "            elif contents.find('references') != -1:\n",
    "                if contents.find( low_name ) != -1:\n",
    "                    get_first_occurence_context_before(contents, low_name, before='references',preview_offset=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e3e720eb-976b-47a8-acfc-014f27e87a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mention_matches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8b45f-8613-4bc4-a0b2-977f5796fefd",
   "metadata": {},
   "source": [
    "## 4. WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85374435-ce78-465a-b3c6-bbbdf0a470dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name in mention_matches:\n",
    "    merged_dict[name]=mention_matches[name]\n",
    "for keyword in keyword_matches:\n",
    "    merged_dict[keyword]=keyword_matches[keyword]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6bf04d-dfe3-4cdd-9779-4b8007e0ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:\n",
    "print(\"* SWITCH TO MULTI-MATCHING\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
