{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3ff45d6-f5c4-44fb-aef7-a9edc0596a90",
   "metadata": {},
   "source": [
    "# PublicDatasets (Analyser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4b8014-f228-46f3-a745-bfb4e63cbc60",
   "metadata": {},
   "source": [
    "## 1. Re-reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17433dfb-a29b-4374-9112-0ad4afa2224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_separator = '___'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba056aa2-a5a2-4c12-923c-814b78cfa6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a553a422-2566-4a43-824b-6baaff9027d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_paper_table = pd.read_csv('data/ResearchPapers.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5f4b519-9ce8-43f3-ba33-e5c5e491e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop ignored\n",
    "research_paper_table\n",
    "research_paper_table = research_paper_table[research_paper_table.included] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd1b100a-f80d-4f13-ac61-88717d87a31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Venue</th>\n",
       "      <th>Title</th>\n",
       "      <th>included</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHIL 2021</td>\n",
       "      <td>Data Augmentation for Electrocardiograms</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHIL 2021</td>\n",
       "      <td>Disability prediction in multiple sclerosis us...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHIL 2021</td>\n",
       "      <td>Practical Challenges in Differentially-Private...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHIL 2021</td>\n",
       "      <td>MedMCQA: A Large-scale Multi-Subject Multi-Cho...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CHIL 2021</td>\n",
       "      <td>Lead-agnostic Self-supervised Learning for Loc...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Venue                                              Title  included\n",
       "1  CHIL 2021           Data Augmentation for Electrocardiograms      True\n",
       "2  CHIL 2021  Disability prediction in multiple sclerosis us...      True\n",
       "3  CHIL 2021  Practical Challenges in Differentially-Private...      True\n",
       "4  CHIL 2021  MedMCQA: A Large-scale Multi-Subject Multi-Cho...      True\n",
       "5  CHIL 2021  Lead-agnostic Self-supervised Learning for Loc...      True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_paper_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d352189-d02b-4723-b92a-e14809c0863b",
   "metadata": {},
   "source": [
    "### 1.a get file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7384f08-4eb9-4fac-97d1-83323d9f309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_filename(v,t,path='data/texts/'):\n",
    "    return path+v+special_separator+t+'.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a0986de-9dc4-4b68-9f93-183afa7591d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for index, row in research_paper_table.iterrows():\n",
    "    texts.append(get_text_filename(row[\"Venue\"],row[\"Title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3e720eb-976b-47a8-acfc-014f27e87a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mention_matches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ca6250-7627-4496-97d7-201b51af1a5c",
   "metadata": {},
   "source": [
    "## 2. Get Dataset Mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa8ace4-411e-4992-b48d-55a57c322689",
   "metadata": {},
   "source": [
    "### 2.1 Get occurences in datasets used in \"Data and Code Availability\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9e9f834-7fae-4e76-92b7-e36b2bd7aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occurences_in_dasa(contents, low_name, before='', preview_offset = 100):\n",
    "    idx0=contents.find(\"data and code availability\")\n",
    "    contents=contents[idx0:]\n",
    "    idx=contents.find(low_name)\n",
    "    if idx==-1: return 0 \n",
    "    idx_end = idx + len(low_name)\n",
    "    L = len(contents)\n",
    "    start_edge = max(0,idx-preview_offset)\n",
    "    end_edge = min(L-1,idx+preview_offset)\n",
    "    print(\"\\33[32mFound\", name, \"in\", text_file,\":\\33[0m\",'\\n',\n",
    "          contents[start_edge:idx]+'\\033[5m\\u001b[31m'+contents[idx:idx_end]+'\\33[0m'+contents[idx_end:end_edge]\n",
    "         )\n",
    "    \n",
    "def get_dasa(contents):\n",
    "    \"\"\"Get the Data and Code Availability section from CHIL papers\"\"\"\n",
    "    idx0=contents.find(\"data and code availability\")\n",
    "    contents=contents[idx0:]\n",
    "    idxend=contents.find('1. introduction')\n",
    "    contents=contents[:idxend]\n",
    "    return contents\n",
    "    #print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "264868cd-d109-4ccc-abfe-240efea801bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mention_matches = {name:[] for name in mentions}\n",
    "items = {text_file:[] for text_file in texts}\n",
    "\n",
    "#limit = 10\n",
    "#i=0\n",
    "for text_file in texts:\n",
    "    #if i>limit: break\n",
    "    with open(text_file, 'r') as f:\n",
    "        contents = f.read()\n",
    "        #Only check for 1-for-1 correspondence\n",
    "        #AND DON'T FORGET TO LOWER CASE WHEN COMPARING!\n",
    "        contents = contents.lower()\n",
    "        #print(contents)\n",
    "\n",
    "        items[text_file] = get_dasa(contents)\n",
    "        #print('{}: ******************'.format(text_file))\n",
    "        #low_name=name.lower()\n",
    "        #if contents.find(low_name) != -1:\n",
    "            #mention_matches[name].append(1)\n",
    "        #    print(get_dasa(contents))\n",
    "        #else:\n",
    "            #mention_matches[name].append(0)\n",
    "        #    pass\n",
    "    #i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f8e20e-65e3-47d1-8c6b-be74665bae66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e549fbc8-2dea-41fd-a0d2-2653ab116a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_section(contents, section_header=\"data and code availability\", section_end=['1. introduction','© 2022']):\n",
    "    \"\"\"Get the Data and Code Availability section from CHIL papers\"\"\"\n",
    "    \n",
    "    contents = contents.lower()\n",
    "    contents = contents.replace(\"\\n\\n\", \"$$$\" )\n",
    "    contents = contents.replace(\"-\\n\", \"\" )\n",
    "    # contents = contents.replace(\"\\n\", \"\" )\n",
    "    contents = contents.replace(\"$$$\", \"\\n\" )\n",
    "\n",
    "    idx0=contents.find(section_header)\n",
    "    contents=contents[idx0:]\n",
    "    for end in section_end:\n",
    "        idxend=contents.find(end)\n",
    "        if idxend==-1: continue\n",
    "        contents=contents[:idxend]\n",
    "        return contents\n",
    "    #print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92870720-f341-4f36-856c-ca5a67dc0083",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "get_dataset_section = get_section(contents, section_header=\"data and code availability\", section_end=['1. introduction','© 2022']):\"\"\"Get the Data and Code Availability section from CHIL papers\"\"\"\n",
    "#REPLACE THE get_dataset_section function to change behavior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24e3fd73-235b-45af-b25e-5ed51e9a75ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "items = {text_file:[] for text_file in texts}\n",
    "\n",
    "for text_file in texts:\n",
    "    with open(text_file, 'r') as f:\n",
    "        contents = f.read()\n",
    "        items[text_file] = get_section(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8b45f-8613-4bc4-a0b2-977f5796fefd",
   "metadata": {},
   "source": [
    "## 4. WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd7f7065-9934-4040-9174-50e142c307aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATTERN 1: Citation\n",
    "# ... [1-2][901]+[ab]*)\n",
    "#\n",
    "# In-line Citation\n",
    "# r'[\\)\\.].* [1-2][901]+[ab]*)'\n",
    "\n",
    "# pat = r'\\(\\D*\\d{4}\\)'\n",
    "# Complete\n",
    "# r'([a-zA-Z ]+[1-2][901]+[ab]*)'\n",
    "def func1(str):\n",
    "    pat = r'\\([^\\d)]*\\d{4}(;\\D*\\d{4})*\\)'\n",
    "    return re.findall(pat,str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87c1a1ae-cf43-46c9-a6ee-5731b91e75f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATTERN 2: Footnote\n",
    "#Footnote\n",
    "\n",
    "\n",
    "def func2(str):\n",
    "    pat = r'[1-9](?!=\\))'\n",
    "    return re.findall(pat,str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ad160e3-9030-4e5d-9318-2b5fbdbae93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATTERN 3: URL\n",
    "#URL Pattern\n",
    "\n",
    "#(https://urlregex.com/)\n",
    "def func3(str):\n",
    "    pat = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    return re.findall(pat,str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4386bfa5-0ab9-40d5-9136-d710c111b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_tokens(pat,str,name,tokens):\n",
    "    matches = re.findall(pat,str)\n",
    "    str = re.sub(pat, '', str)\n",
    "    tokens |= {name: matches}\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "53c4c383-fc5a-47d3-870b-36ddc8ab21be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\\n?t\\n?t\\n?p\\n?[s]?\\n?:\\n?/\\n?/\\n?(?:[a-zA-Z\\n?]|[0-9]|[$-_@.&+]|[!*\\(\\\\n?),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\n"
     ]
    }
   ],
   "source": [
    "xn = r'\\n?' #optional newline\n",
    "son = r'(?: |\\n)' #space or newline\n",
    "\n",
    "author = r\"(?:[A-Za-z'`-]+)\"\n",
    "etal = r\"(?:et al\\.?)\"\n",
    "additional = f\"(?:{xn},?{son}(?:(?:and |& )?{author}|{etal}))\"\n",
    "year_num = \"(?:19|20)[0-9][0-9]\"\n",
    "page_num = \"(?:, p\\.? [0-9]+)?\"  # Always optional\n",
    "year = fr\"(?:, *{year_num}{page_num}| *\\({year_num}{page_num}\\))\"\n",
    "inline_citation = fr'\\b(?!(?:Although|Also)\\b){xn}{author}{xn}{additional}*{xn}{year}'\n",
    "# ADAPTED FROM https://stackoverflow.com/a/63633049/2089784\n",
    "\n",
    "num_section = r'([0-9]\\.)+[0-9]'\n",
    "url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'  #https://urlregex.com/\n",
    "split_url_pattern = fr'h{xn}t{xn}t{xn}p{xn}[s]?{xn}:{xn}/{xn}/{xn}(?:[a-zA-Z{xn}]|[0-9]|[$-_@.&+]|[!*\\(\\{xn}),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "\n",
    "footnote_pattern = r'(?:(?<=[a-zA-Z\\.]) ?|,)[1-9](?![\\)\\d])'\n",
    "\n",
    "print(split_url_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1287fe8d-d48c-4035-90de-c4f396d83954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_newlines(dict):\n",
    "    for key, val in dict.items():\n",
    "        dict[key] = [ s.replace('\\n','') for s in val ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "85374435-ce78-465a-b3c6-bbbdf0a470dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'In-line Citation': ['wagner et al., 2020', 'goldbergeret al., 2000'], 'URL': ['https://github.com/aniruddhraghu/ecg_aug.'], 'Footnote': []}\n",
      "ADD AN ERROR\n",
      "{'In-line Citation': [], 'URL': [], 'Footnote': [' 1']}\n",
      "{'In-line Citation': [], 'URL': [], 'Footnote': []}\n",
      "{'In-line Citation': ['reyna et al., 2021', 'wagner et al., 2020'], 'URL': ['https://github.com/jwoo5/fairseq-signals'], 'Footnote': ['1']}\n",
      "{'In-line Citation': ['johnsonet al., 2019', 'irvin et al., 2019', 'johnson et al., 2021', 'goldberger et al., 2000', 'irvin et al., 2019'], 'URL': ['https://github.com/mlforhealth/cxr_fairness.'], 'Footnote': [' 1']}\n",
      "{'In-line Citation': ['johnson et al., 2016', 'fivez et al., 2017', 'lu et al., 2019'], 'URL': ['https://github.com/dalgu90/cim-misspelling.'], 'Footnote': []}\n",
      "{'In-line Citation': ['johnson et al., 2016', 'johnsonet al., 2016'], 'URL': ['https://github.com/sjpark9503/kg_txt_multimodal'], 'Footnote': ['1']}\n",
      "{'In-line Citation': ['carnicelli et al., 2021'], 'URL': ['https://github.com/mary-wu/smdp.'], 'Footnote': []}\n",
      "{'In-line Citation': ['hyland et al., 2020'], 'URL': ['https://physionet.org/content/hirid//the', 'https://github.com/addison-weatherhead/trace'], 'Footnote': [' 1']}\n",
      "{'In-line Citation': [], 'URL': [], 'Footnote': []}\n",
      "{'In-line Citation': [], 'URL': [], 'Footnote': ['1']}\n",
      "{'In-line Citation': [], 'URL': ['http://adni.loni.usc.edu).', 'http://adni.loni.usc.edu/wp-content/uploads/how_to_apply/adni_acknowledgement_list.pdf', 'https://github.com/healthy-ai/adcb.'], 'Footnote': []}\n",
      "{'In-line Citation': ['curtiset al., 2012', 'knaus et al., 1995', 'kvamme et al., 2019'], 'URL': [], 'Footnote': ['1', '2']}\n",
      "{'In-line Citation': ['johnson et al., 2016', 'pollard et al., 2018'], 'URL': ['https://github.com/hoon9405/descemb'], 'Footnote': ['1']}\n",
      "{'In-line Citation': ['johnson et al., 2016'], 'URL': ['https://github.com/xiaoleihuang/useremb_explainable.1.', 'https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/,', 'https://physionet.org/content/mimiciii//.'], 'Footnote': ['1', ' 2']}\n",
      "{'In-line Citation': ['ohdsi, 2019'], 'URL': ['https://github.com/ki-research-institute/external-evaluation.'], 'Footnote': []}\n",
      "{'In-line Citation': ['brooks-gunn et al., 1992', 'schwab et al., 2018'], 'URL': ['https://github.com/vdorie/npci2.', 'https://archive.ics.uci.edu/ml/datasets/bag+of+words'], 'Footnote': []}\n",
      "{'In-line Citation': [], 'URL': ['https://clinicaltrials.gov/.'], 'Footnote': []}\n",
      "{'In-line Citation': ['oberst and sontag, 2019'], 'URL': ['https://github.com/mlforhealth/counterfactual_transfer.1.', 'https://github.com/clinicalml/gumbel-max-scm'], 'Footnote': ['1']}\n",
      "{'In-line Citation': [], 'URL': ['https://isip.piconepress.com/projects/tuh', 'https://github.com/aitrics/eeg'], 'Footnote': []}\n",
      "{'In-line Citation': ['rossiet al., 2020'], 'URL': ['https://github.com/rossialessio/mmash.'], 'Footnote': []}\n",
      "{'In-line Citation': ['johnson et al., 2016', 'goldberger et al., 2000', 'gottesmanet al., 2019', 'jiang and li(2016)', 'thomas and brunskill (2016)', 'kallus and uehara (2020)', 'komorowski et al. (2018)'], 'URL': [], 'Footnote': [' 6']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for name in mention_matches:\n",
    "#     merged_dict[name]=mention_matches[name]\n",
    "# for keyword in keyword_matches:\n",
    "#     merged_dict[keyword]=keyword_matches[keyword]\n",
    "\n",
    "# NEW CSV USING get_dasa function from 3.4\n",
    "\n",
    "# for item in items:\n",
    "#     print(item)\n",
    "#     print(items[item])\n",
    "\n",
    "for title, context in items.items():\n",
    "    # print(func(pd.DataFrame( [ items[item] for item in items] ).iloc[i][0]))\n",
    "    # print([ items[item] for item in items][i])\n",
    "    # print(texts[i])\n",
    "    # print(func1(pd.DataFrame( [ items[item] for item in items] ).iloc[i][0]))\n",
    "    # print(func2(pd.DataFrame( [ items[item] for item in items] ).iloc[i][0]))\n",
    "    # print(func3())\n",
    "    \n",
    "    references = {}\n",
    "    # block = pd.DataFrame( [ items[item] for item in items] ).iloc[i][0]\n",
    "    block = context\n",
    "    \n",
    "    if (type(block) == type(None)):\n",
    "        print(\"ADD AN ERROR\")\n",
    "        continue\n",
    "    \n",
    "    block = collect_tokens(inline_citation,block,\"In-line Citation\",references)\n",
    "    block = collect_tokens(num_section,block,\"Numbered Section\",{})\n",
    "    block = collect_tokens(split_url_pattern,block,\"URL\",references)\n",
    "    block = collect_tokens(footnote_pattern,block,\"Footnote\",references) \n",
    "    \n",
    "    clean_newlines(references)\n",
    "    \n",
    "    print(references)\n",
    "    \n",
    "# texts[18]\n",
    "\n",
    "# print(pd.DataFrame( [ items[item] for item in items] ).iloc[2][0])\n",
    "\n",
    "# TODO: MAKE THESE INTO ROWS FOR THE CSV SHEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3e6bf04d-dfe3-4cdd-9779-4b8007e0ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TODO:\n",
    "# print(\"* SWITCH TO MULTI-MATCHING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127cbc28-e1ce-43d4-a5e1-f507fb5a5427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
